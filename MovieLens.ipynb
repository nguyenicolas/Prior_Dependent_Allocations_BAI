{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 364,
     "status": "ok",
     "timestamp": 1652373079763,
     "user": {
      "displayName": "Imad Aouali",
      "userId": "10957666911602104909"
     },
     "user_tz": 240
    },
    "id": "dUrLMhAcZYDY",
    "outputId": "e7637e0a-2d44-4760-e4d6-bcbb43502924",
    "tags": []
   },
   "source": [
    "# Notebook for Bayesian Best-Arm Idenfitication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.9.13\n",
      "matplotlib 3.5.2\n",
      "8 joblib cores\n"
     ]
    }
   ],
   "source": [
    "# Imports and defaults\n",
    "import itertools\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.linalg import block_diag\n",
    "import scipy.optimize as spo\n",
    "from scipy import optimize\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from numpy.linalg import pinv\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "mpl.style.use(\"classic\")\n",
    "mpl.rcParams[\"figure.figsize\"] = [5, 3]\n",
    "\n",
    "mpl.rcParams[\"axes.linewidth\"] = 0.75\n",
    "mpl.rcParams[\"figure.facecolor\"] = \"w\"\n",
    "mpl.rcParams[\"grid.linewidth\"] = 0.75\n",
    "mpl.rcParams[\"lines.linewidth\"] = 0.75\n",
    "mpl.rcParams[\"patch.linewidth\"] = 0.75\n",
    "mpl.rcParams[\"xtick.major.size\"] = 3\n",
    "mpl.rcParams[\"ytick.major.size\"] = 3\n",
    "\n",
    "mpl.rcParams[\"pdf.fonttype\"] = 42\n",
    "mpl.rcParams[\"ps.fonttype\"] = 42\n",
    "mpl.rcParams[\"font.size\"] = 9\n",
    "mpl.rcParams[\"axes.titlesize\"] = \"medium\"\n",
    "mpl.rcParams[\"legend.fontsize\"] = \"medium\"\n",
    "\n",
    "import platform\n",
    "print(\"python %s\" % platform.python_version())\n",
    "print(\"matplotlib %s\" % mpl.__version__)\n",
    "print(\"%d joblib cores\" % joblib.cpu_count())\n",
    "\n",
    "def linestyle2dashes(style):\n",
    "  if style == \"--\":\n",
    "    return (3, 3)\n",
    "  elif style == \":\":\n",
    "    return (0.5, 2.5)\n",
    "  else:\n",
    "    return (None, None)\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def norm2_matrix(x, A) :\n",
    "    return x.T @ A @ x\n",
    "\n",
    "def fac_compute_Sigma_hat_n(n, omega, A, Sigma_0_inv):\n",
    "    sum_ = A.T.dot(n * omega[:, None] * A)\n",
    "    return np.linalg.inv(Sigma_0_inv + sum_)\n",
    "\n",
    "def fac_Cova_hat_mu_n(sigma, omega, Sigma_0, A, Sigma_hat_n, n):\n",
    "    K, d = A.shape\n",
    "    \n",
    "    helper_ = n * omega * (sigma**2 + np.sum(A.dot(Sigma_0) * A, axis=1))\n",
    "    variance_terms = A.T.dot(helper_[:, None] * A)\n",
    "    \n",
    "    helper1 = np.outer(n*omega, n*omega)\n",
    "    helper2 = A.dot(Sigma_0)\n",
    "    helper2 = A.dot(helper2.T)\n",
    "    helper12 = helper1 * helper2\n",
    "\n",
    "    A_flatten = A.flatten().reshape(-1, 1)\n",
    "    outer_products = A_flatten.dot(A_flatten.T)\n",
    "    outer_products = outer_products.reshape(K, d, K, d)\n",
    "    outer_products = outer_products.swapaxes(1, 2)\n",
    "    weighted_outer_products = helper12[:, :, None, None] * outer_products\n",
    "    covariance_terms = np.sum(weighted_outer_products, axis=(0, 1)) - np.trace(weighted_outer_products, axis1=0, axis2=1)\n",
    "    \n",
    "    Cova_hat_mu_n_result = (1/sigma**4) * np.dot(np.dot(Sigma_hat_n, variance_terms + covariance_terms), Sigma_hat_n)\n",
    "    \n",
    "    return Cova_hat_mu_n_result\n",
    "\n",
    "\n",
    "def fac_kappa(A, mu_0, Cov_hat_mu_n, m):\n",
    "    K, _ = A.shape\n",
    "    diff_Aj_Am = A - A[m]\n",
    "    results = np.zeros(K)\n",
    "    outer_products = np.einsum('ij,ik->ijk', diff_Aj_Am, diff_Aj_Am)\n",
    "    weighted_mu_0 = np.einsum('ijk,k->ij', outer_products, mu_0)\n",
    "    norm_mu_0 = np.einsum('ik,k->i', weighted_mu_0, mu_0)\n",
    "    weighted_diff_Aj_Am = diff_Aj_Am.dot(Cov_hat_mu_n) \n",
    "    norm_diff_Aj_Am = np.einsum('ik,ik->i', weighted_diff_Aj_Am, diff_Aj_Am)\n",
    "    norm_diff_Aj_Am[m] = 1e-50 #To avoid dividing by 0\n",
    "    results = np.exp(-norm_mu_0 / norm_diff_Aj_Am) \n",
    "    results[m] = 1\n",
    "    return results\n",
    "\n",
    "\n",
    "def fac_upper_bound_linear(omega, sigma, mu_0, Sigma_0, A, n):\n",
    "    K, d = A.shape\n",
    "    result = 0\n",
    "    Sigma_0_inv = np.linalg.inv(Sigma_0)\n",
    "    m = np.argmax(mu_0)\n",
    "    \n",
    "    Sigma_hat_n = fac_compute_Sigma_hat_n(n, omega, A, Sigma_0_inv)\n",
    "    Cov_hat_mu_n = fac_Cova_hat_mu_n(sigma, omega, Sigma_0, A, Sigma_hat_n, n)   \n",
    "    \n",
    "    ### Computing Lambda_val\n",
    "    diff_matrix = A[:, np.newaxis] - A\n",
    "    \n",
    "    weighted_diff_matrix1 = diff_matrix.dot(Sigma_hat_n)\n",
    "    norm_diff_Ai_Aj_Sigma = np.einsum('ijk,ijk->ij', weighted_diff_matrix1, diff_matrix)\n",
    "\n",
    "    weighted_diff_matrix2 = diff_matrix.dot(Cov_hat_mu_n)\n",
    "    norm_diff_Ai_Aj_Cova = np.einsum('ijk,ijk->ij', weighted_diff_matrix2, diff_matrix)\n",
    "    \n",
    "    weighted_diff_matrix3 = diff_matrix.dot(Sigma_0)\n",
    "    norm_diff_Ai_Aj_Sigma_0 = np.einsum('ijk,ijk->ij', weighted_diff_matrix3, diff_matrix)\n",
    "\n",
    "    weighted_outer_products = np.einsum('ijk,ijl->ijkl', weighted_diff_matrix2, diff_matrix)\n",
    "    weighted_outer_products = weighted_outer_products/(2*norm_diff_Ai_Aj_Sigma_0[:,:,None,None]+1e-50) #Check how to handle Nan issues using helper_stabilizer \n",
    "    #helper_stabilizer = np.tile(1e-30*np.eye(d), (K, K, 1, 1)) #Check how to handle Nan issues using helper_stabilizer\n",
    "\n",
    "    term = np.tile(np.eye(d), (K, K, 1, 1)) - weighted_outer_products\n",
    "    Lambda_val = np.einsum('ik,nmkj->nmij', np.linalg.inv(Cov_hat_mu_n), term)\n",
    "    \n",
    "    term1 =1 / np.sqrt(1 + (norm_diff_Ai_Aj_Cova / (norm_diff_Ai_Aj_Sigma + 1e-50)))\n",
    "    weighted_mu_0 = Lambda_val.dot(mu_0)\n",
    "    norm_mu_0 = np.einsum('ijk,k->ij', weighted_mu_0, mu_0)\n",
    "    term2 = np.exp(-0.5 * norm_mu_0)\n",
    "    result = term1 * term2\n",
    "\n",
    "    return np.sum(result) - np.trace(result)\n",
    "\n",
    "def adjust_multi(w):\n",
    "  w_new = np.asarray(w).astype('float64')\n",
    "  return w_new / np.sum(w_new)\n",
    "\n",
    "\n",
    "def compute_w_opt_one(cons, bounds, sigma, mu_0, Sigma_0, action_matrix, n, alpha) :\n",
    "    \n",
    "    K, _ = np.shape(action_matrix)\n",
    "    marginal_variances =  np.array([action_matrix[i].T @ Sigma_0 @ action_matrix[i] for i in range(K)]) \n",
    "    \n",
    "    p_start = np.random.random(K) \n",
    "    p_start = p_start / np.sum(p_start)\n",
    "    cons = [({'type':'eq', 'fun': lambda p: np.linalg.norm(p, 1) - 1})]\n",
    "    bounds = tuple([(0, 1) for _ in range(K)])\n",
    "    w_opt = optimize.minimize(fac_upper_bound_linear, p_start, args=(sigma, mu_0, Sigma_0, action_matrix, n), bounds=bounds, constraints=cons).x\n",
    "\n",
    "    w_tilde_tmp =  np.array([mu_0 @ action_matrix[i] for i in range(K)]) * marginal_variances / np.sum(marginal_variances)\n",
    "    w_tilde = w_tilde_tmp / np.sum(w_tilde_tmp)\n",
    "\n",
    "    tmp_w_mix = alpha * w_opt + (1 - alpha) * w_tilde \n",
    "    w = tmp_w_mix / np.sum(tmp_w_mix)\n",
    "\n",
    "    return w\n",
    "\n",
    "def compute_w_opt(sigma, mu_0, Sigma_0, action_matrix, n, alpha, num_MC=50) :\n",
    "   \n",
    "   cons = [({'type':'eq', 'fun': lambda p: np.linalg.norm(p, 1) - 1})]\n",
    "   bounds = tuple([(0, 1) for _ in range(K)])\n",
    "   \n",
    "   w_opt_matrix = Parallel(n_jobs=-1)(delayed(compute_w_opt_one)(cons, bounds, sigma, mu_0, Sigma_0, action_matrix, n, alpha) for ex in tqdm(range(num_MC)))\n",
    "   w_opt_final = w_opt_matrix[np.argmin([fac_upper_bound_linear(omega, sigma, mu_0, Sigma_0, action_matrix, n) for omega in w_opt_matrix])]\n",
    "   return adjust_multi(w_opt_final)\n",
    "\n",
    "def generate_random_action_matrix_gaussian(K, d) :\n",
    "    action_matrix = np.zeros((K, d))\n",
    "    for i in range(K) :\n",
    "        random_vect = np.random.multivariate_normal(np.ones(d), np.eye(d))\n",
    "        action_matrix[i] = random_vect / np.linalg.norm(random_vect, 1)\n",
    "    return action_matrix\n",
    "\n",
    "def objective_func(pi, n, K, action_matrix, Sigma_0_inv, sigma) :\n",
    "    somme_helper = 0\n",
    "    for i in range(K) :\n",
    "        somme_helper+= pi[i] * n * np.outer(action_matrix[i], action_matrix[i])\n",
    "    s, logdet = np.linalg.slogdet(Sigma_0_inv + somme_helper/(sigma**2))\n",
    "    return - s * logdet\n",
    "\n",
    "\n",
    "def BG_opt(n, K, action_matrix, Sigma_0_inv, sigma, num_mc = 10) :\n",
    "\n",
    "    values = np.zeros(num_mc)\n",
    "    vectors = np.zeros((num_mc, K))\n",
    "\n",
    "    p_start = np.random.random(K)  #TODO: play with initialization\n",
    "    p_start = p_start / np.sum(p_start)\n",
    "    cons = [({'type':'eq', 'fun': lambda p: np.linalg.norm(p, 1) - 1})]\n",
    "    bounds = tuple([(0, 1) for _ in range(K)])\n",
    "\n",
    "    for i in range(num_mc) :\n",
    "        p_start = np.random.random(K)  #TODO: play with initialization\n",
    "        p_start = p_start / np.sum(p_start)\n",
    "        result = optimize.minimize(objective_func, p_start, args=(n, K, action_matrix, Sigma_0_inv, sigma), bounds=bounds, constraints=cons)\n",
    "        w_opt = result.x\n",
    "        values[i] = result.fun\n",
    "        vectors[i, :] = w_opt\n",
    "\n",
    "    w_opt = vectors[np.argmin(values), :]\n",
    "    return w_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bandit Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "id": "f7uZWkUjRmUs",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bandit environments\n",
    "class LinearBanditEnvironment(object):\n",
    "  \"\"\"Contextual bandit with K arms.\"\"\"\n",
    "\n",
    "  def __init__(self, actions_matrix, theta, sigma):\n",
    "    self.actions_matrix = actions_matrix\n",
    "    self.K, self.d = np.shape(self.actions_matrix)  # number of arms\n",
    "    self.theta = np.copy(theta)  # list of reward means\n",
    "    self.sigma = sigma  # reward noise\n",
    "    self.best_arm = np.argmax([self.theta @ action for action in actions_matrix])\n",
    "    #self.randomize()\n",
    "\n",
    "  #def randomize(self):\n",
    "  #  self.rt = self.theta + self.sigma * np.random.randn(self.K)\n",
    "\n",
    "  def reward(self, arm_index):\n",
    "    # instantaneous reward of the arm\n",
    "    return self.actions_matrix[arm_index].T @ self.theta + self.sigma * np.random.randn()\n",
    "\n",
    "  def print(self):\n",
    "    return \"Bandit Environment: %d arms\" % (self.K)\n",
    "\n",
    "def evaluate_one(Alg, env, n):\n",
    "  \"\"\"One run of a bandit algorithm.\"\"\"\n",
    "  alg = Alg(env, n)\n",
    "  alg.explore(n)\n",
    "  J_n = alg.get_best_arm()\n",
    "  return 1 * (J_n != env.best_arm)\n",
    "\n",
    "\n",
    "def evaluate(Alg, env, n, printout=False):\n",
    "  \"\"\"Multiple runs of a bandit algorithm.\"\"\"\n",
    "  start = time.time()\n",
    "  num_exps = len(env)\n",
    "  error_indicators = Parallel(n_jobs=-1)(delayed(evaluate_one)(Alg, env[ex], n) for ex in range(num_exps))\n",
    "  error_indicators = np.array(error_indicators)\n",
    "  error_prob = np.mean(error_indicators)\n",
    "\n",
    "  if printout:\n",
    "    print(\"Evaluating %s\" % Alg.print(), end=\"\")\n",
    "    print(\" %.1f seconds\" % (time.time() - start))\n",
    "    print(\"Probability of error: %.2f +/- %.2f\" %(np.mean(error_indicators), np.std(error_indicators) / np.sqrt(num_exps)))\n",
    "\n",
    "  return error_prob, error_indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_one_sr(Alg, env, n):\n",
    "  \"\"\"One run of a bandit algorithm.\"\"\"\n",
    "  alg = Alg(env, n)\n",
    "  alg.explore(n)\n",
    "  J_n = alg.get_best_arm()\n",
    "  return env.theta.dot(env.actions_matrix[env.best_arm]) - env.theta.dot(env.actions_matrix[J_n])\n",
    "\n",
    "\n",
    "def evaluate_sr(Alg, env, n, printout=False):\n",
    "  \"\"\"Multiple runs of a bandit algorithm.\"\"\"\n",
    "  start = time.time()\n",
    "  num_exps = len(env)\n",
    "  error_indicators = Parallel(n_jobs=-1)(delayed(evaluate_one_sr)(Alg, env[ex], n) for ex in range(num_exps))\n",
    "  error_indicators = np.array(error_indicators)\n",
    "  error_prob = np.mean(error_indicators)\n",
    "\n",
    "  if printout:\n",
    "    print(\"Evaluating %s\" % Alg.print(), end=\"\")\n",
    "    print(\" %.1f seconds\" % (time.time() - start))\n",
    "    print(\"Probability of error: %.2f +/- %.2f\" %(np.mean(error_indicators), np.std(error_indicators) / np.sqrt(num_exps)))\n",
    "\n",
    "  return error_prob, error_indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BAI Algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BAI algorithm that assumes that sigma_0 is the same for all arms and allocates n_i = n//K for each arm\n",
    "class BAIUniform:\n",
    "  def __init__(self, env, n):\n",
    "    self.env = env  # bandit environment that the agent interacts with\n",
    "    self.actions_matrix = self.env.actions_matrix  # number of arms\n",
    "    self.K, self.d = np.shape(self.actions_matrix)\n",
    "    self.n = n  # budget\n",
    "    self.mu_0 = np.copy(env.mu_0)  # list of prior means \\mu_{0, i} for i=1,..., K\n",
    "    self.Sigma_0 = np.copy(env.Sigma_0)  # list of prior standard deviations \\sigma_{0, i} for i=1,..., K\n",
    "    self.Sigma_0_inv = np.copy(env.Sigma_0_inv)\n",
    "    self.sigma = env.sigma  # reward noise\n",
    "\n",
    "    # sufficient statistics\n",
    "    self.B = np.zeros(self.d) # sum of observed rewards for each arm\n",
    "    self.n_i = np.zeros(self.K) # n_i is a list containing the number of pulls of each arm\n",
    "\n",
    "  def update(self, arm, r):\n",
    "    # update sufficient statistics\n",
    "    self.B += r * self.actions_matrix[arm]\n",
    "    self.n_i[arm] += 1\n",
    "    \n",
    "  def explore(self, n):\n",
    "    # explore actions\n",
    "    for i in range(self.K):\n",
    "        for t in range(self.n//self.K):\n",
    "            #self.env.randomize()\n",
    "            # update statistics\n",
    "            self.update(i, self.env.reward(i))\n",
    "  \n",
    "  def get_best_arm(self):\n",
    "    # compute posterior means\n",
    "    self.mu = np.zeros(self.K)\n",
    "    # arm parameter posterior\n",
    "    somme_helper = 0\n",
    "    for i in range(self.K) :\n",
    "       somme_helper+= self.n_i[i] * np.outer(self.actions_matrix[i], self.actions_matrix[i])\n",
    "       \n",
    "    Sigma_hat_helper = self.Sigma_0_inv + somme_helper / self.sigma**2\n",
    "    sigma_hat_square = np.linalg.inv(Sigma_hat_helper) \n",
    "    self.mu = sigma_hat_square @ ( self.Sigma_0_inv @ self.mu_0 + self.B / self.sigma**2 )\n",
    "    arm = np.argmax([self.mu.T @ self.actions_matrix[i] for i in range(self.K)])\n",
    "    #print(\"list pulls = \", self.n_i)\n",
    "    #print(\"somme = \", np.sum(self.n_i))\n",
    "    return arm\n",
    "\n",
    "  @staticmethod\n",
    "  def print():\n",
    "    return \"BAI-Uni\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BAI algorithm that assumes that sigma_0 is the same for all arms and allocates n_i = n//K for each arm\n",
    "class BAIOpt:\n",
    "  def __init__(self, env, n):\n",
    "    self.env = env  # bandit environment that the agent interacts with\n",
    "    self.actions_matrix = self.env.actions_matrix  # number of arms\n",
    "    self.K, self.d = np.shape(self.actions_matrix)\n",
    "    self.n = n  # budget\n",
    "    self.mu_0 = np.copy(env.mu_0)  # list of prior means \\mu_{0, i} for i=1,..., K\n",
    "    self.Sigma_0 = np.copy(env.Sigma_0)  # list of prior standard deviations \\sigma_{0, i} for i=1,..., K\n",
    "    self.Sigma_0_inv = np.copy(env.Sigma_0_inv)\n",
    "    self.sigma = env.sigma  # reward noise\n",
    "    self.w_optim = self.env.w_optim\n",
    "    self.n_samples = np.random.multinomial(self.n, self.w_optim)\n",
    "\n",
    "    # sufficient statistics\n",
    "    self.B = np.zeros(self.d) # sum of observed rewards for each arm\n",
    "    self.n_i = np.zeros(self.K) # n_i is a list containing the number of pulls of each arm\n",
    "\n",
    "  def update(self, arm, r):\n",
    "    # update sufficient statistics\n",
    "    self.B += r * self.actions_matrix[arm]\n",
    "    self.n_i[arm] += 1\n",
    "    \n",
    "  def explore(self, n):\n",
    "    # explore actions\n",
    "    for i in range(self.K):\n",
    "        for t in range(self.n_samples[i]):\n",
    "            #self.env.randomize()\n",
    "            # update statistics\n",
    "            self.update(i, self.env.reward(i))\n",
    "  \n",
    "  def get_best_arm(self):\n",
    "    # compute posterior means\n",
    "    self.mu = np.zeros(self.K)\n",
    "    # arm parameter posterior\n",
    "    somme_helper = 0\n",
    "    for i in range(self.K) :\n",
    "       somme_helper+= self.n_i[i] * np.outer(self.actions_matrix[i], self.actions_matrix[i])\n",
    "       \n",
    "    Sigma_hat_helper = self.Sigma_0_inv + somme_helper / self.sigma**2\n",
    "    sigma_hat_square = np.linalg.inv(Sigma_hat_helper) \n",
    "    self.mu = sigma_hat_square @ ( self.Sigma_0_inv @ self.mu_0 + self.B / self.sigma**2 )\n",
    "    arm = np.argmax([self.mu.T @ self.actions_matrix[i] for i in range(self.K)])\n",
    "    #print(\"list pulls = \", self.n_i)\n",
    "    #print(\"somme = \", np.sum(self.n_i))\n",
    "    return arm\n",
    "\n",
    "  @staticmethod\n",
    "  def print():\n",
    "    return \"BAI-Opt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BAI algorithm that assumes that sigma_0 is the same for all arms and allocates n_i = n//K for each arm\n",
    "class BAIOptimalDesign:\n",
    "  def __init__(self, env, n):\n",
    "    self.env = env  # bandit environment that the agent interacts with\n",
    "    self.actions_matrix = self.env.actions_matrix  # number of arms\n",
    "    self.K, self.d = np.shape(self.actions_matrix)\n",
    "    self.n = n  # budget\n",
    "    self.mu_0 = np.copy(env.mu_0)  # list of prior means \\mu_{0, i} for i=1,..., K\n",
    "    self.Sigma_0 = np.copy(env.Sigma_0)  # list of prior standard deviations \\sigma_{0, i} for i=1,..., K\n",
    "    self.Sigma_0_inv = np.copy(env.Sigma_0_inv)\n",
    "    self.sigma = self.env.sigma  # reward noise\n",
    "    self.w_optimal_design = self.env.w_optimal_design\n",
    "    self.n_samples = np.random.multinomial(self.n, self.w_optimal_design)\n",
    "\n",
    "    # sufficient statistics\n",
    "    self.B = np.zeros(self.d) # sum of observed rewards for each arm\n",
    "    self.n_i = np.zeros(self.K) # n_i is a list containing the number of pulls of each arm\n",
    "\n",
    "  def update(self, arm, r):\n",
    "    # update sufficient statistics\n",
    "    self.B += r * self.actions_matrix[arm]\n",
    "    self.n_i[arm] += 1\n",
    "    \n",
    "  def explore(self, n):\n",
    "    # explore actions\n",
    "    for i in range(self.K):\n",
    "        for t in range(self.n_samples[i]):\n",
    "            #self.env.randomize()\n",
    "            # update statistics\n",
    "            self.update(i, self.env.reward(i))\n",
    "  \n",
    "  def get_best_arm(self):\n",
    "    # compute posterior means\n",
    "    self.mu = np.zeros(self.K)\n",
    "    # arm parameter posterior\n",
    "    somme_helper = 0\n",
    "    for i in range(self.K) :\n",
    "       somme_helper+= self.n_i[i] * np.outer(self.actions_matrix[i], self.actions_matrix[i])\n",
    "       \n",
    "    Sigma_hat_helper = self.Sigma_0_inv + somme_helper / self.sigma**2\n",
    "    sigma_hat_square = np.linalg.inv(Sigma_hat_helper) \n",
    "    self.mu = sigma_hat_square @ ( self.Sigma_0_inv @ self.mu_0 + self.B / self.sigma**2 )\n",
    "    arm = np.argmax([self.mu.T @ self.actions_matrix[i] for i in range(self.K)])\n",
    "    #print(\"list pulls = \", self.n_i)\n",
    "    #print(\"somme = \", np.sum(self.n_i))\n",
    "    return arm\n",
    "\n",
    "  @staticmethod\n",
    "  def print():\n",
    "    return \"BAI-Opt-design\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BAI algorithm that assumes that sigma_0 is the same for all arms and allocates n_i = n//K for each arm\n",
    "class AdaBAIRandom:\n",
    "  def __init__(self, env, n):\n",
    "    self.env = env  # bandit environment that the agent interacts with\n",
    "    self.actions_matrix = self.env.actions_matrix  # number of arms\n",
    "    self.K, self.d = np.shape(self.actions_matrix)\n",
    "    self.n = n  # budget\n",
    "    self.mu_0 = np.copy(env.mu_0)  # list of prior means \\mu_{0, i} for i=1,..., K\n",
    "    self.Sigma_0 = np.copy(env.Sigma_0)  # list of prior standard deviations \\sigma_{0, i} for i=1,..., K\n",
    "    self.Sigma_0_inv = np.copy(env.Sigma_0_inv)\n",
    "    self.sigma = self.env.sigma  # reward noise\n",
    "    self.w_rd = self.env.w_rd\n",
    "    self.n_samples = np.random.multinomial(self.n, self.w_rd)\n",
    "\n",
    "    # sufficient statistics\n",
    "    self.B = np.zeros(self.d) # sum of observed rewards for each arm\n",
    "    self.n_i = np.zeros(self.K) # n_i is a list containing the number of pulls of each arm\n",
    "\n",
    "\n",
    "  def update(self, arm, r):\n",
    "    # update sufficient statistics\n",
    "    self.B += r * self.actions_matrix[arm]\n",
    "    self.n_i[arm] += 1\n",
    "    \n",
    "  def explore(self, n):\n",
    "    # explore actions\n",
    "    for i in range(self.K):\n",
    "        for t in range(self.n_samples[i]):\n",
    "            #self.env.randomize()\n",
    "            # update statistics\n",
    "            self.update(i, self.env.reward(i))\n",
    "  \n",
    "  def get_best_arm(self):\n",
    "    # compute posterior means\n",
    "    self.mu = np.zeros(self.K)\n",
    "    # arm parameter posterior\n",
    "    somme_helper = 0\n",
    "    for i in range(self.K) :\n",
    "       somme_helper+= self.n_i[i] * np.outer(self.actions_matrix[i], self.actions_matrix[i])\n",
    "       \n",
    "    Sigma_hat_helper = self.Sigma_0_inv + somme_helper / self.sigma**2\n",
    "    sigma_hat_square = np.linalg.inv(Sigma_hat_helper) \n",
    "    self.mu = sigma_hat_square @ ( self.Sigma_0_inv @ self.mu_0 + self.B / self.sigma**2 )\n",
    "    arm = np.argmax([self.mu.T @ self.actions_matrix[i] for i in range(self.K)])\n",
    "    #print(\"list pulls = \", self.n_i)\n",
    "    #print(\"somme = \", np.sum(self.n_i))\n",
    "    return arm\n",
    "\n",
    "  @staticmethod\n",
    "  def print():\n",
    "    return \"AdaBAI-Random\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAI algorithm with different values of sigma_{0, i} and that learns the allocations n_i by optimizing the bound C_bayes\n",
    "class GSE:\n",
    "  \n",
    "  def __init__(self, env, n):\n",
    "    self.env = env  # bandit environment that the agent interacts with\n",
    "    self.n = n  # budget\n",
    "    self.nb_rounds = int(np.ceil(np.log(env.d) / np.log(2)))\n",
    "    self.budget_per_round = int(np.ceil(n / self.nb_rounds))\n",
    "\n",
    "    self.actions_matrix = env.actions_matrix # active set of arms\n",
    "    self.active_arms_index = np.arange(env.K) \n",
    "    self.active_arms_vector = np.copy(self.actions_matrix)[self.active_arms_index]\n",
    "\n",
    "  def update(self, k, r, last_bool):\n",
    "    # last_bool = True when this is the last round of the phase\n",
    "\n",
    "    # update V_t and b_t :\n",
    "    if last_bool == False :\n",
    "      self.V+= np.outer(self.actions_matrix[k], self.actions_matrix[k])\n",
    "      self.b+= self.actions_matrix[k] * r\n",
    "\n",
    "    # update theta at the end of the round, and eliminate bad arms\n",
    "    else :\n",
    "      self.mu = dict.fromkeys(self.active_arms_index, 0) # restart estimator of mu\n",
    "      \n",
    "      # compute estimate of theta\n",
    "      self.theta = pinv(self.V) @ self.b\n",
    "\n",
    "      # compute rmean estimates\n",
    "      for k in self.active_arms_index :\n",
    "         self.mu[k] = self.theta @ self.actions_matrix[k]\n",
    "      \n",
    "      # get new active set\n",
    "      self.mu_sorted = {k: v for k, v in sorted(self.mu.items(), key=lambda item: item[1])} #np.argsort(self.mu)[len(self.active_arms_index):]\n",
    "\n",
    "      # eliminate half of arms\n",
    "      active_arms_index_new = list(self.mu_sorted.keys())[len(self.active_arms_index)//2:]\n",
    "      self.active_arms_index = active_arms_index_new\n",
    "      # store associated arm vectors\n",
    "      self.active_arms_vector = np.copy(self.actions_matrix)[self.active_arms_index, :]\n",
    "      \n",
    "  def explore(self, n):\n",
    "\n",
    "    for r in range(self.nb_rounds) :# for each round\n",
    "\n",
    "      # draft observations from previous rounds\n",
    "      self.V = 0\n",
    "      self.b = 0\n",
    "\n",
    "      # explore using G-optimal design\n",
    "      pi_r = self.optimal_design()\n",
    "\n",
    "      n_samples = np.random.multinomial(self.budget_per_round, pi_r)\n",
    "\n",
    "      for cpt, k in enumerate(self.active_arms_index) : # for all arm in the active set\n",
    "        for i in range(n_samples[cpt]) : # pull this arm according to G-opt\n",
    "          r = self.env.reward(k)\n",
    "          self.update(k, r, last_bool=False)\n",
    "\n",
    "      self.update(None, None, last_bool=True)\n",
    "    \n",
    "  def get_best_arm(self):\n",
    "\n",
    "    # return the only arm that belongs to active set\n",
    "    return max(self.mu_sorted, key=self.mu_sorted.get) # return the last item if there is one element, else the maximum (if there was not enough budget to run additional rounds)\n",
    "\n",
    "  def optimal_design(self):\n",
    "      # This function is from https://github.com/Azizimj/StructuredBAI/blob/main/optDesign.py\n",
    "      cur_num_arms = (self.active_arms_vector).shape[0]\n",
    "      \"\"\"Frank Wolfe\"\"\"\n",
    "      pi = np.ones(cur_num_arms) / cur_num_arms  # pi_0 in Frank Wolfe\n",
    "      X_copy = [a.reshape(self.env.d, 1) for a in self.active_arms_vector]\n",
    "      eps = 1e-1\n",
    "      lambda_ = .001\n",
    "      gpi_k = float('inf')\n",
    "      k = 0\n",
    "\n",
    "      while gpi_k > self.env.d + eps and k<100:\n",
    "          k += 1\n",
    "          Vpi_k = lambda_ * np.eye(self.env.d)\n",
    "          for i, a in enumerate(X_copy):\n",
    "              Vpi_k += pi[i] * np.dot(a, a.T)\n",
    "          # Vpi_k = np.matrix.sum([pi[i] * a * a.T for i, a in enumerate(X)])\n",
    "          Vpi_k = np.linalg.inv(Vpi_k)\n",
    "          a_Vpi = [np.dot(np.dot(a.T, Vpi_k), a) for a in X_copy]\n",
    "          a_k_idx = np.argmax(a_Vpi)\n",
    "          gpi_k = a_Vpi[a_k_idx]\n",
    "          a_k = X_copy[a_k_idx]\n",
    "          gamma_ = ((1 / self.env.d * gpi_k - 1) / (gpi_k - 1))[0][0]\n",
    "          pi *= (1 - gamma_)\n",
    "          pi[a_k_idx] += gamma_\n",
    "      # print(k)\n",
    "      pi_sum = np.sum(pi)\n",
    "      if pi_sum != 1:\n",
    "          # rnd_idx = np.random.randint(0, num_arms)\n",
    "          rnd_idx = np.argmax(pi)\n",
    "          pi[rnd_idx] = 1 - pi_sum + pi[rnd_idx]\n",
    "      return np.array(pi)\n",
    "\n",
    "  @staticmethod\n",
    "  def print():\n",
    "    return \"GSE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Thompson sampling algorithms that are only used to estimate the best allocations n_i\n",
    "class LinTS:\n",
    "  \n",
    "  def __init__(self, env, n):\n",
    "    self.env = env  # bandit environment that the agent interacts with\n",
    "    self.actions_matrix = self.env.actions_matrix\n",
    "    self.K, self.d = np.shape(self.actions_matrix)  # number of arms\n",
    "    self.n = n  # budget\n",
    "    self.mu_0 = np.copy(env.mu_0)  # list of prior means \\mu_{0, i} for i=1,..., K\n",
    "    self.Sigma_0 = np.copy(env.Sigma_0)  # list of prior standard deviations \\sigma_{0, i} for i=1,..., K\n",
    "    self.Sigma_0_inv = np.copy(env.Sigma_0_inv)\n",
    "    self.sigma = self.env.sigma  # reward noise\n",
    "\n",
    "    # sufficient statistics\n",
    "    self.B = np.zeros(self.d) # sum of observed rewards for each arm\n",
    "    self.n_i = np.zeros(self.K) # n_i is a list containing the number of pulls of each arm\n",
    "\n",
    "  def update(self, arm, r):\n",
    "    # update sufficient statistics\n",
    "    self.B += r * self.actions_matrix[arm]\n",
    "    self.n_i[arm] += 1\n",
    "    \n",
    "  def get_arm(self):\n",
    "    # compute posterior means\n",
    "\n",
    "    somme_helper = 0\n",
    "    for i in range(self.K) :\n",
    "       somme_helper += self.n_i[i] * np.outer(self.actions_matrix[i], self.actions_matrix[i])\n",
    "    \n",
    "    Sigma_hat_helper = self.Sigma_0_inv + somme_helper / self.sigma**2\n",
    "    Sigma_hat = np.linalg.inv(Sigma_hat_helper) \n",
    "    mu_hat = Sigma_hat @ ( self.Sigma_0_inv @ self.mu_0 + self.B / self.sigma**2 )\n",
    "\n",
    "    self.mu = np.random.multivariate_normal(mu_hat, Sigma_hat) # TODO : cholesky decomposition for quicker computation ?\n",
    "    arm = np.argmax([self.mu.T @ self.actions_matrix[i] for i in range(self.K)])\n",
    "    return arm\n",
    "\n",
    "  @staticmethod\n",
    "  def print():\n",
    "    return \"LinTS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BAI algorithm with different values of sigma_{0, i} and that learns the allocations n_i by running TS in a warm-up phase\n",
    "class BAILinTS:\n",
    "  def __init__(self, env, n):\n",
    "    self.env = env  # bandit environment that the agent interacts with\n",
    "    self.actions_matrix = self.env.actions_matrix\n",
    "    self.K, self.d = np.shape(self.actions_matrix) # number of arms\n",
    "    self.n_ts = self.env.n_ts # TS exploration budget\n",
    "    self.n = n - self.n_ts # budget TODO: check if it does not affect anything\n",
    "    self.mu_0 = np.copy(env.mu_0)  # list of prior means \\mu_{0, i} for i=1,..., K\n",
    "    self.Sigma_0 = np.copy(env.Sigma_0)  # list of prior standard deviations \\sigma_{0, i} for i=1,..., K\n",
    "    self.Sigma_0_inv = np.copy(env.Sigma_0_inv)\n",
    "    self.sigma = self.env.sigma  # reward noise\n",
    "            \n",
    "    ts_alg = LinTS(self.env, self.n_ts)\n",
    "    for _ in range(self.n_ts):\n",
    "        arm = ts_alg.get_arm()\n",
    "        ts_alg.update(arm, env.reward(arm))\n",
    "    self.w_LinTS = ts_alg.n_i / self.n_ts  \n",
    "    self.n_samples = np.random.multinomial(self.n, self.w_LinTS)\n",
    "\n",
    "    # sufficient statistics\n",
    "    self.B = np.zeros(self.d) # sum of observed rewards for each arm\n",
    "    self.n_i = np.zeros(self.K) # n_i is a list containing the number of pulls of each arm\n",
    "\n",
    "  def update(self, arm, r):\n",
    "    # update sufficient statistics\n",
    "    self.B += r * self.actions_matrix[arm]\n",
    "    self.n_i[arm] += 1\n",
    "\n",
    "  def explore(self, n):\n",
    "    # explore actions\n",
    "    for i in range(self.K):\n",
    "        for t in range(self.n_samples[i]):\n",
    "            #self.env.randomize()\n",
    "            # update statistics\n",
    "            self.update(i, self.env.reward(i))\n",
    "  \n",
    "  def get_best_arm(self):\n",
    "    # compute posterior means\n",
    "    self.mu = np.zeros(self.K)\n",
    "    # arm parameter posterior\n",
    "    somme_helper = 0\n",
    "    for i in range(self.K) :\n",
    "       somme_helper+= self.n_i[i] * np.outer(self.actions_matrix[i], self.actions_matrix[i])\n",
    "    \n",
    "    Sigma_hat_helper = self.Sigma_0_inv + somme_helper / self.sigma**2\n",
    "    sigma_hat_square = np.linalg.inv(Sigma_hat_helper) \n",
    "    self.mu = sigma_hat_square @ ( self.Sigma_0_inv @ self.mu_0 + self.B / self.sigma**2 )\n",
    "    arm = np.argmax([self.mu.T @ self.actions_matrix[i] for i in range(self.K)])\n",
    "    return arm\n",
    "\n",
    "  @staticmethod\n",
    "  def print():\n",
    "    return \"BAI-LinTS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BAI algorithm that assumes that sigma_0 is the same for all arms and allocates n_i = n//K for each arm\n",
    "class BayesGap:\n",
    "  \"\"\"\n",
    "  Some parts of the code have been derived from https://github.com/Azizimj/StructuredBAI/blob/main/StructBAI.py\n",
    "  \"\"\"\n",
    "  def __init__(self, env, n):\n",
    "    self.env = env  # bandit environment that the agent interacts with\n",
    "    self.actions_matrix = self.env.actions_matrix  # number of arms\n",
    "    self.K, self.d = np.shape(self.actions_matrix)\n",
    "    self.n = n  # budget\n",
    "    self.mu_0 = np.copy(env.mu_0)  # list of prior means \\mu_{0, i} for i=1,..., K\n",
    "    self.Sigma_0 = np.copy(env.Sigma_0)  # list of prior standard deviations \\sigma_{0, i} for i=1,..., K\n",
    "    self.Sigma_0_inv = np.copy(env.Sigma_0_inv)\n",
    "    self.sigma = self.env.sigma  # reward noise\n",
    "\n",
    "    self.eta = np.sqrt(np.mean(np.diag(self.Sigma_0))) # FIRST ASSUME DIAGONAL COVARIANCE\n",
    "    self.epsilon = 1e-5 # very small because we minimize PoE.\n",
    "    self.kappa = np.sum([ 1/np.linalg.norm(self.actions_matrix[i], 2)**2 for i in range(self.K) ])\n",
    "\n",
    "    # sufficient statistics\n",
    "    self.B = np.zeros(self.d) # sum of observed rewards for each arm\n",
    "    self.n_i = np.zeros(self.K) # n_i is a list containing the number of pulls of each arm\n",
    "    self.hist_Jt, self.hist_jt = [], []\n",
    "    self.recom, self.recom_BJt = None, float('inf')\n",
    "\n",
    "  def update(self, arm, r):\n",
    "    # update sufficient statistics\n",
    "    self.B += r * self.actions_matrix[arm]\n",
    "    self.n_i[arm] += 1\n",
    "    \n",
    "  def explore(self, n):\n",
    "    # explore actions\n",
    "    for t in range(self.K) :\n",
    "      self.update(t, self.env.reward(t))\n",
    "\n",
    "    for t in range(self.n - self.K) :\n",
    "\n",
    "      self.compute_posterior()\n",
    "      j_t, J_t = self.compute_BayesGap_params()\n",
    "      \n",
    "      a_t = J_t if self.s_t[J_t] >= self.s_t[j_t] else j_t\n",
    "      self.update(a_t, self.env.reward(a_t))\n",
    "      \n",
    "  def compute_BayesGap_params(self):\n",
    "\n",
    "    upbs, lowbs = self.mu_hat + 3 * np.sqrt(self.sigma2_hat), self.mu_hat - 3 * np.sqrt(self.sigma2_hat)\n",
    "    upbs_argmax = np.argmax(upbs)\n",
    "    second_best_tmp_1 = np.sort(upbs, axis=0)[-2]\n",
    "    delta_hats = [upbs[upbs_argmax]-lowbs[i] for i in range(self.K)]\n",
    "    delta_hats[upbs_argmax] = second_best_tmp_1 - lowbs[upbs_argmax]  # delta for the maximizer of upbs\n",
    "    H_epsilon = np.sum([ 1/(max(0.5*(delta_hats[i]+self.epsilon),self.epsilon))**2 for i in range(self.K)])\n",
    "    #bseeta = beta_numerator/Heps\n",
    "    self.beta = np.sqrt(( (self.n - self.K)/(self.sigma**2) + self.kappa/(self.eta**2) ) / (4 * H_epsilon))\n",
    "    \n",
    "    U_t = self.mu_hat + self.beta * np.sqrt(self.sigma2_hat)\n",
    "    L_t = self.mu_hat - self.beta * np.sqrt(self.sigma2_hat)\n",
    "\n",
    "    argmax_U = np.argmax(U_t)\n",
    "    second_best_tmp_2 = np.sort(U_t)[-2]\n",
    "    B_t = [U_t[argmax_U] - L_t[k] for k in range(self.K)]\n",
    "    B_t[argmax_U] = second_best_tmp_2 - L_t[argmax_U]\n",
    "\n",
    "    J_t = np.argmin(B_t)\n",
    "    U_t_tmp = 1*U_t\n",
    "    U_t_tmp[J_t] = -np.inf\n",
    "    j_t = np.argmax(U_t_tmp)\n",
    "    \n",
    "    self.hist_Jt.append(J_t)\n",
    "    self.hist_jt.append(j_t)\n",
    "\n",
    "    self.s_t = 2 * self.beta * np.sqrt(self.sigma2_hat)\n",
    "\n",
    "    if B_t[J_t] < self.recom_BJt:\n",
    "      self.recom, self.recom_BJt = J_t, B_t[J_t]\n",
    "\n",
    "    return j_t, J_t\n",
    "    \n",
    "  def compute_posterior(self):\n",
    "    \n",
    "    # arm parameter posterior\n",
    "    somme_helper = 0\n",
    "    for i in range(self.K) :\n",
    "       somme_helper+= self.n_i[i] * np.outer(self.actions_matrix[i], self.actions_matrix[i])\n",
    "       \n",
    "    Sigma_hat_helper = self.Sigma_0_inv + somme_helper / self.sigma**2\n",
    "    Sigma_hat = np.linalg.inv(Sigma_hat_helper) \n",
    "    self.theta_hat = Sigma_hat @ ( self.Sigma_0_inv @ self.mu_0 + self.B / self.sigma**2 )\n",
    "    self.mu_hat = np.array([self.theta_hat.T @ self.actions_matrix[i] for i in range(self.K)])\n",
    "    self.sigma2_hat = np.array([self.actions_matrix[i].T @ Sigma_hat @ self.actions_matrix[i] for i in range(self.K)])\n",
    "  \n",
    "  def get_best_arm(self):\n",
    "    # compute posterior means\n",
    "    if self.recom == None :\n",
    "      print(\"FLAG\") # sanity check\n",
    "    return self.recom if self.recom != None else -1\n",
    "\n",
    "  @staticmethod\n",
    "  def print():\n",
    "    return \"BayesGap\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fb52ff260e4608a001fb003c72f477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.748 0.879 0.829 0.820 0.817 0.815 0.815 0.814 0.814 0.813 0.813 0.813 0.813 0.813 0.813 0.812 0.812 0.812 0.812 0.812 \n",
      "Movie means    : 1.076 -1.203 -0.592 -1.935 0.940\n",
      "Movie variances: 0.344 0.392 0.352 0.803 0.549\n"
     ]
    }
   ],
   "source": [
    "def ALS(M, W, d, num_iter=20):\n",
    "  num_rows = M.shape[0]\n",
    "  num_cols = M.shape[1]\n",
    "  U = 2 * np.random.rand(num_rows, d) - 1\n",
    "  V = 2 * np.random.rand(num_cols, d) - 1\n",
    "  \n",
    "  reg = 1.0\n",
    "  for iter in tqdm(range(num_iter)):\n",
    "    for i in range(num_rows):\n",
    "      sel = np.flatnonzero(W[i, :])\n",
    "      G = V[sel, :].T.dot(V[sel, :]) + reg * np.eye(d)\n",
    "      U[i, :] = np.linalg.solve(G, V[sel, :].T.dot(M[i, sel]))\n",
    "    for j in range(num_cols):\n",
    "      sel = np.flatnonzero(W[:, j])\n",
    "      G = U[sel, :].T.dot(U[sel, :]) + reg * np.eye(d)\n",
    "      V[j, :] = np.linalg.solve(G, U[sel, :].T.dot(M[sel, j]))\n",
    "    print(\"%.3f \" % (np.linalg.norm(W * (M - U.dot(V.T))) / np.sqrt(W.sum())), end=\"\")\n",
    "  print()\n",
    "  \n",
    "  return U, V\n",
    "\n",
    "D = np.loadtxt(\"ratings.txt\")\n",
    "D = D[:, : 3].astype(int)\n",
    "num_users = D[:, 0].max()\n",
    "num_movies = D[:, 1].max()\n",
    "D[:, : 2] = D[:, : 2] - 1\n",
    "\n",
    "M = np.zeros((num_users, num_movies))\n",
    "M[D[:, 0], D[:, 1]] = D[:, 2]\n",
    "W = np.zeros((num_users, num_movies))\n",
    "W[D[:, 0], D[:, 1]] = 1\n",
    "\n",
    "ndx = np.random.permutation(num_users)\n",
    "M = M[ndx, :]\n",
    "W = W[ndx, :]\n",
    "\n",
    "d = 5\n",
    "users, movies = ALS(M, W, d=d)\n",
    "\n",
    "np.random.shuffle(users)\n",
    "np.random.shuffle(movies)\n",
    "\n",
    "mu_movie = movies.mean(axis=0)\n",
    "var_movie = movies.var(axis=0)\n",
    "print(\"Movie means    : %s\" % \" \".join(\"%.3f\" % s for s in mu_movie))\n",
    "print(\"Movie variances: %s\" % \" \".join(\"%.3f\" % s for s in var_movie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mu_user = users.mean(axis=0)\n",
    "var_user = users.var(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6040"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLens experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21bd0c9dad9405f85fc32d897be11a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments with n = 150\n",
      "\n",
      "\n",
      "('BayesGap', 'green', '-', 'BayesGap')\n",
      "('BAILinTS', 'cyan', '-', 'BAI-LinTS')\n",
      "('BAIUniform', 'green', '-', 'BAI-Uni')\n",
      "('BAIOpt', 'black', '-', 'BAI-Opt')\n",
      "('BAIOptimalDesign', 'red', '-', 'BAI-Opt-design')\n",
      "('GSE', 'red', '-', 'GSE')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c9867addd3f444aabd9a40e6a10bb25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments with n = 250\n",
      "\n",
      "\n",
      "('BayesGap', 'green', '-', 'BayesGap')\n",
      "('BAILinTS', 'cyan', '-', 'BAI-LinTS')\n",
      "('BAIUniform', 'green', '-', 'BAI-Uni')\n",
      "('BAIOpt', 'black', '-', 'BAI-Opt')\n",
      "('BAIOptimalDesign', 'red', '-', 'BAI-Opt-design')\n",
      "('GSE', 'red', '-', 'GSE')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7994fe99af5d485ea59dcfd436347365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments with n = 350\n",
      "\n",
      "\n",
      "('BayesGap', 'green', '-', 'BayesGap')\n",
      "('BAILinTS', 'cyan', '-', 'BAI-LinTS')\n",
      "('BAIUniform', 'green', '-', 'BAI-Uni')\n",
      "('BAIOpt', 'black', '-', 'BAI-Opt')\n",
      "('BAIOptimalDesign', 'red', '-', 'BAI-Opt-design')\n",
      "('GSE', 'red', '-', 'GSE')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb1a2ea67594c6b95747cc1416cfe3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments with n = 450\n",
      "\n",
      "\n",
      "('BayesGap', 'green', '-', 'BayesGap')\n",
      "('BAILinTS', 'cyan', '-', 'BAI-LinTS')\n",
      "('BAIUniform', 'green', '-', 'BAI-Uni')\n",
      "('BAIOpt', 'black', '-', 'BAI-Opt')\n",
      "('BAIOptimalDesign', 'red', '-', 'BAI-Opt-design')\n",
      "('GSE', 'red', '-', 'GSE')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e15c359c9744aafa6a9fdbf7cec4c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments with n = 550\n",
      "\n",
      "\n",
      "('BayesGap', 'green', '-', 'BayesGap')\n",
      "('BAILinTS', 'cyan', '-', 'BAI-LinTS')\n",
      "('BAIUniform', 'green', '-', 'BAI-Uni')\n",
      "('BAIOpt', 'black', '-', 'BAI-Opt')\n",
      "('BAIOptimalDesign', 'red', '-', 'BAI-Opt-design')\n",
      "('GSE', 'red', '-', 'GSE')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92234ee093a94b4f84457f87a911b01c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments with n = 650\n",
      "\n",
      "\n",
      "('BayesGap', 'green', '-', 'BayesGap')\n",
      "('BAILinTS', 'cyan', '-', 'BAI-LinTS')\n",
      "('BAIUniform', 'green', '-', 'BAI-Uni')\n",
      "('BAIOpt', 'black', '-', 'BAI-Opt')\n",
      "('BAIOptimalDesign', 'red', '-', 'BAI-Opt-design')\n",
      "('GSE', 'red', '-', 'GSE')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53d0c855ddb4a41b3d4b672bcbcc222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments with n = 750\n",
      "\n",
      "\n",
      "('BayesGap', 'green', '-', 'BayesGap')\n",
      "('BAILinTS', 'cyan', '-', 'BAI-LinTS')\n",
      "('BAIUniform', 'green', '-', 'BAI-Uni')\n",
      "('BAIOpt', 'black', '-', 'BAI-Opt')\n",
      "('BAIOptimalDesign', 'red', '-', 'BAI-Opt-design')\n",
      "('GSE', 'red', '-', 'GSE')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085294190de04eb5904ce8e2989b9e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments with n = 850\n",
      "\n",
      "\n",
      "('BayesGap', 'green', '-', 'BayesGap')\n",
      "('BAILinTS', 'cyan', '-', 'BAI-LinTS')\n",
      "('BAIUniform', 'green', '-', 'BAI-Uni')\n",
      "('BAIOpt', 'black', '-', 'BAI-Opt')\n",
      "('BAIOptimalDesign', 'red', '-', 'BAI-Opt-design')\n",
      "('GSE', 'red', '-', 'GSE')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4e70877287466998d996a78cc34059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments with n = 950\n",
      "\n",
      "\n",
      "('BayesGap', 'green', '-', 'BayesGap')\n",
      "('BAILinTS', 'cyan', '-', 'BAI-LinTS')\n",
      "('BAIUniform', 'green', '-', 'BAI-Uni')\n",
      "('BAIOpt', 'black', '-', 'BAI-Opt')\n",
      "('BAIOptimalDesign', 'red', '-', 'BAI-Opt-design')\n",
      "('GSE', 'red', '-', 'GSE')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "843ff7cc9e294ac5b5163e791c90e547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments with n = 1050\n",
      "\n",
      "\n",
      "('BayesGap', 'green', '-', 'BayesGap')\n",
      "('BAILinTS', 'cyan', '-', 'BAI-LinTS')\n",
      "('BAIUniform', 'green', '-', 'BAI-Uni')\n",
      "('BAIOpt', 'black', '-', 'BAI-Opt')\n",
      "('BAIOptimalDesign', 'red', '-', 'BAI-Opt-design')\n",
      "('GSE', 'red', '-', 'GSE')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b9f258a5b5a47c38fa28e72f7c220a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments with n = 1150\n",
      "\n",
      "\n",
      "('BayesGap', 'green', '-', 'BayesGap')\n",
      "('BAILinTS', 'cyan', '-', 'BAI-LinTS')\n",
      "('BAIUniform', 'green', '-', 'BAI-Uni')\n",
      "('BAIOpt', 'black', '-', 'BAI-Opt')\n",
      "('BAIOptimalDesign', 'red', '-', 'BAI-Opt-design')\n",
      "('GSE', 'red', '-', 'GSE')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e5eab5831742d3acfb976a5f3b2d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments with n = 1250\n",
      "\n",
      "\n",
      "('BayesGap', 'green', '-', 'BayesGap')\n",
      "('BAILinTS', 'cyan', '-', 'BAI-LinTS')\n",
      "('BAIUniform', 'green', '-', 'BAI-Uni')\n",
      "('BAIOpt', 'black', '-', 'BAI-Opt')\n",
      "('BAIOptimalDesign', 'red', '-', 'BAI-Opt-design')\n",
      "('GSE', 'red', '-', 'GSE')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d323a0f19018474790d3bd769f2f3f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments with n = 1350\n",
      "\n",
      "\n",
      "('BayesGap', 'green', '-', 'BayesGap')\n",
      "('BAILinTS', 'cyan', '-', 'BAI-LinTS')\n",
      "('BAIUniform', 'green', '-', 'BAI-Uni')\n",
      "('BAIOpt', 'black', '-', 'BAI-Opt')\n",
      "('BAIOptimalDesign', 'red', '-', 'BAI-Opt-design')\n",
      "('GSE', 'red', '-', 'GSE')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a98197732a34640bf42a268b0576f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments with n = 1450\n",
      "\n",
      "\n",
      "('BayesGap', 'green', '-', 'BayesGap')\n",
      "('BAILinTS', 'cyan', '-', 'BAI-LinTS')\n",
      "('BAIUniform', 'green', '-', 'BAI-Uni')\n",
      "('BAIOpt', 'black', '-', 'BAI-Opt')\n",
      "('BAIOptimalDesign', 'red', '-', 'BAI-Opt-design')\n",
      "('GSE', 'red', '-', 'GSE')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c9f77b725245eca5470a95cf86b34e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments with n = 1550\n",
      "\n",
      "\n",
      "('BayesGap', 'green', '-', 'BayesGap')\n",
      "('BAILinTS', 'cyan', '-', 'BAI-LinTS')\n",
      "('BAIUniform', 'green', '-', 'BAI-Uni')\n",
      "('BAIOpt', 'black', '-', 'BAI-Opt')\n",
      "('BAIOptimalDesign', 'red', '-', 'BAI-Opt-design')\n",
      "('GSE', 'red', '-', 'GSE')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eebf2a9b92542b898dd500ce61876ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments with n = 1650\n",
      "\n",
      "\n",
      "('BayesGap', 'green', '-', 'BayesGap')\n",
      "('BAILinTS', 'cyan', '-', 'BAI-LinTS')\n",
      "('BAIUniform', 'green', '-', 'BAI-Uni')\n",
      "('BAIOpt', 'black', '-', 'BAI-Opt')\n",
      "('BAIOptimalDesign', 'red', '-', 'BAI-Opt-design')\n",
      "('GSE', 'red', '-', 'GSE')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79519cb86e864a05894b693c6e7ae701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments with n = 1750\n",
      "\n",
      "\n",
      "('BayesGap', 'green', '-', 'BayesGap')\n",
      "('BAILinTS', 'cyan', '-', 'BAI-LinTS')\n",
      "('BAIUniform', 'green', '-', 'BAI-Uni')\n",
      "('BAIOpt', 'black', '-', 'BAI-Opt')\n",
      "('BAIOptimalDesign', 'red', '-', 'BAI-Opt-design')\n",
      "('GSE', 'red', '-', 'GSE')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35318b9e82af4ab4abd42cc5ee91728d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments with n = 1850\n",
      "\n",
      "\n",
      "('BayesGap', 'green', '-', 'BayesGap')\n",
      "('BAILinTS', 'cyan', '-', 'BAI-LinTS')\n",
      "('BAIUniform', 'green', '-', 'BAI-Uni')\n",
      "('BAIOpt', 'black', '-', 'BAI-Opt')\n",
      "('BAIOptimalDesign', 'red', '-', 'BAI-Opt-design')\n",
      "('GSE', 'red', '-', 'GSE')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c715102d96495baf44c7c2c077fea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments with n = 1950\n",
      "\n",
      "\n",
      "('BayesGap', 'green', '-', 'BayesGap')\n",
      "('BAILinTS', 'cyan', '-', 'BAI-LinTS')\n",
      "('BAIUniform', 'green', '-', 'BAI-Uni')\n",
      "('BAIOpt', 'black', '-', 'BAI-Opt')\n",
      "('BAIOptimalDesign', 'red', '-', 'BAI-Opt-design')\n",
      "('GSE', 'red', '-', 'GSE')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd0286e0880>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAADjCAYAAABZ7tX3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAxOAAAMTgF/d4wjAABPMUlEQVR4nO2deVzVVf7/n3cB7mVHkF1lR7hsLmhqmVlpZVnaZlOj5dg3y7Zpm2qmyWlqqnGWFueXNTWT1ahtYzblUpbZorngDi4IKsgOsl24XLj3nt8fH7iAoAJe4Arn+Xicx2c7n3POPcCLc9/nfd5HJYQQSCQSicSpUPd3AyQSiUTSESnOEolE4oRIcZZIJBInRIqzRCKROCFSnCUSicQJkeIskUgkTogUZ4lEInFCuizO69evJz4+npiYGF566aVO83z33XekpaVhMBi49NJLHdZIiUQiGWyourIIxWq1EhcXx9dff014eDjp6emsXLmSxMREe56qqiomTpzI+vXrGT58OKWlpQQGBvZq4yUSiWSg0qWR8/bt24mJiSEqKgpXV1fmzJnDmjVr2uVZsWIFs2fPZvjw4QBSmCUSieQ86JI4FxQUMGzYMPt1eHg4BQUF7fIcOXKEyspKpkyZwpgxY3jvvfcc21KJRCIZRGi7kqkzy4dKpWp3bbFYyMjI4JtvvsFkMjFhwgQuuugi4uLiHNNSiUQiGUR0SZzDw8PJz8+3X588eZLQ0NAOeQICAvDw8MDDw4PJkyezd+/eDuLs5uaGp6cnAB4eHvZzydkxGo2yr7qJ7LOeIfutaxiNRurq6uznZrPZsRWILtDU1CQiIyNFbm6uMJvNIiUlRRw4cKBdnqysLDF16lTR1NQk6urqhMFgEPv37+9Q1pAhQ7pSpeQ0fv3rX/d3Ey44ZJ/1DNlv3ac3dK1LI2etVsvSpUuZPn06VquV+fPnYzAYWLZsGQALFy4kISGBq666ipSUFNRqNQsWLCApKcmx/0kkEolkkNAlVzpHMnz4cPLy8vqyygHBhg0bmD59en8344JC9lnPkP3WfXpD1/pcnBMTE8nKyurLKiUSiaRX6Q1d65JZQyKROJYpU6ZQWlra382Q9IDAwEC+++67Xq9HirNE0g+UlpbKb5AXKG1XRvcmMvCRRCKROCFSnCUSicQJkeIskQxSNBoNaWlppKamMnr0aLZs2dIn9VosFp5++mliY2NJS0sjLS2NF154oU/qvpCQNmeJZJCi1+vZs2cPoLjPPfXUU2zevLnX6/3d735HcXEx+/fvR6fTUVtby1//+tder/dCQ46cJRIJNTU1+Pn5AcpS5Msvv5zRo0eTnJxsj0D5zDPP8Oqrr9rf+e1vf8trr70GwJIlS0hPTyclJYVnn30WgLq6OmbMmEFqaipJSUl8+OGH1NfX889//pPXX38dnU4HgJeXF4sXL7aXe8MNNzBmzBgMBgNvvfWW/b6npyePPvooo0eP5vLLL6esrKxX+6Tfcfiaw3OQkJDQ11VKJE6HM/wdqNVqkZqaKuLj44W3t7fYuXOnEEIJ11BdXS2EEKKsrExER0cLm80mjh07JkaNGiWEEMJqtYqoqChRXl4uNmzYIO6++25hs9mE1WoVM2bMEJs3bxaffPKJWLBggb2+qqoqsXfvXpGWlnbWdlVUVAghhKivrxcGg0GUl5cLIYQAxAcffCCEEOIPf/iDWLRokWM7pIt09rPrjZ+nNGtIJE7GpElQWdn99/z84Kefup6/rVlj69atzJ07lwMHDiCE4Omnn+b7779HrVZTUFBASUkJERER+Pv7s3v3bkpKShg1ahT+/v589dVXfPXVV4waNQpQRt7Z2dlccsklPPbYY/zmN7/h2muv5ZJLLunQhn//+9+8+uqrVFRUsGXLFoYNG8Zrr73G6tWrAcjPzyc7Oxt/f3/UajW33norAHfccQezZ8/ufiddQEhxlkicjO4IrKOYMGEC5eXllJWVsXbtWsrKysjIyMDFxYWIiAgaGhoAWLBgAe+++y7FxcXMnz8fUEIKP/XUU9xzzz0dys3IyGDt2rU89dRTTJs2jccee4y8vDxqa2vx8vLirrvu4q677iIpKQmr1cp3333Hxo0b2bp1K+7u7kyZMsVe9+mcHrZ4oCFtzhKJhEOHDmG1WvH396e6uprAwEBcXFzYtGkTJ06csOebNWsW69evZ8eOHfb4G9OnT+df//oXRqMRUDbnKC0tpbCwEHd3d+644w4ee+wxdu3ahbu7O7/61a+4//777aJrtVppbGwEoLq6Gj8/P9zd3Tl06BA///yzvW6bzcYnn3wCKDsvXXzxxX3SN/2FHDlLJIMUk8lEWloaoIx+ly9fjkaj4fbbb+e6665j7NixpKWlMXLkSPs7rq6uXHbZZfj6+qLRaACYNm0aBw8eZMKECYAycffBBx9w9OhRHn/8cdRqNS4uLrzxxhsAvPDCCzzzzDMkJSXh5eWFXq9n3rx5hIaGEhISwrJly0hJSSE+Pp6LLrrIXreHhweZmZmMGTMGHx8fPvzwwz7qqf5BBj6SSPqBC/XvwGazMXr0aD7++GNiY2P7tG5PT0/76Lw/6exn1xs/T2nWkEgkXSIrK4uYmBguv/zyPhfmwYg0a0gkki6RmJhIbm5uv9XvDKPmvkSOnCUSicQJkeIskUgkTogUZ4lEInFCpDhLJBKJEyLFWSIZpJwrZOjf//53dDod1dXV9nvfffcd1157baflTZkyhZ07d7a7t3PnTh588MEztqGiosIeNjQ4OJiwsDD7dWNjIy+88AIGg4GUlBTS0tLYtm3beXziCwvprSGRDFLOFTJ05cqVpKens3r1au68884e1TF27FjGjh17xuf+/v72NixevBhPT08ee+wxQIn38cUXX7Br1y7c3NwoLy+3ryQcDMiRs0QiaRcyFCAnJwej0cjzzz/PypUre1xu25H24sWLmT9/PlOmTCEqKsoebvRMFBUVERAQgJubGwABAQGEhob2uC0XGl0W5/Xr1xMfH09MTAwvvfRSh+ffffcdPj4+9q8kzz33nEMbKpFIHEvL8u2RI0eyYMECnnnmGfuzlStXctttt3HJJZdw+PBhh+0UfujQITZs2MD27dv5wx/+QFNT0xnzTps2jfz8fOLi4rjvvvv6ZCMAZ6JLZg2r1cqiRYv4+uuvCQ8PJz09nZkzZ3bYhfaSSy7hiy++6JWGSiSDhUn/mkSlqfsxQ/30fvw0v+sh7c4UMlSlUrFq1SpWr16NWq1m9uzZfPzxxyxatKjbbTqdGTNm4ObmhpubG4GBgZSUlBAeHt5pXk9PTzIyMvjhhx/YtGkTt956Ky+99FKPTSwXGl0S5+3btxMTE0NUVBQAc+bMYc2aNX22RXhXKS9fw5AhV6NWu/Z3UySSHtMdgXUUbUOGFhcXk52dzZVXXglAY2MjUVFRHcR5+vTplJSUMHbsWN5+++0u1dNiogBlQtJisZw1v0ajYcqUKUyZMoXk5GSWL18+aMS5S2aNgoIChg0bZr8ODw+noKCgQ76tW7eSmprK1VdfTWZmpuNa2UWqq7dSVPSvPq9XIrnQaRsydOXKlSxevJjjx49z/PhxCgsLKSgoaBc6FJRJxD179nRZmLvL4cOHyc7Otl/v2bOHESNG9EpdzkiXRs6dBa47PdD16NGjOXHiBJ6enqxdu5YbbrihXcf2BcOGPcaePZMJDr4TjUbXp3VLJBcaZwoZumrVKtatW9cu76xZs1i1ahXjx48/a5kzZszAxcUFUEbj52MKMRqNPPDAA1RVVaHVaomJiWm3p+BAp0shQ7du3crixYvZsGEDAC+++CIATz311BnfiYiIYOfOnQQEBLS7P3z4cG666SZA+VrUErDbUeTm/g5X12DCw+93aLkSiSO5UEOGSlp/dhs2bLBr4ieffEJeXp5D6+nSyDk9PZ3s7GyOHTtGWFgYq1atYsWKFe3yFBcXExQUhEqlYvv27dhsNvz9/TuU5enpyd/+9jfHtL4Thg17hN27JxES8is0Gn2v1SORSAY3bQeX69evd3j5XbI5a7Vali5dyvTp00lISOCWW27BYDCwbNkyli1bBij/OZKSkkhNTeXBBx9k1apVfb7H16s/v4rJpmXo0FspKho8X38kEsnAY0DthPLMt88Q4RvB3OQb2b17AmPGZKDRuPdKXRLJ+SDNGhcucieUHnBn2p28u/ddXFx8CQy8ncLCN/q7SRKJRNIjBpQ4Rw+JRqPScKTiCOHhD1JU9DYWy+DaPUEikQwMBpQ4Q/Poec+7aLXeBAXNo7DwH/3dJIlEIuk2A06cb0q8idWHVmO1WQkLu5/i4nexWGr6u1kSidPh6JChERERlJeXdylvWyZOnNjDTzCwGXDi7OnqyYTwCXyd+zVarSfBwb+ioOD1/m6WROJ0tMTW2Lt3Ly+++GKHdQttQ4b2Jqf/U5AoDDhxBrgr7S7+veffAISF3UdJyQdYLNXneEsiGbz0VsjQFs4WLtTT0/O8yx+IDMhg+xcPv5j71t7HKdMphuiHEBJyDydPvkJExLP93TSJxGloWb7d0NBAUVER3377rf1ZZyFDAwMDz6u+Q4cOsWnTJmpra4mPj+fee++1L/WWdGRAirNKpWKOYQ4r969k0bhFhIbeQ0bGGMLCHsTFxe/cBUgk/cmkSVDZ/ZCh+PnBT/0XMrSzRWdt73UnXKhkgIozwNzUudz08U0sGrcIjUZPaOh9nDz5NyIj/9jfTZNIzk43BNZROCJkqL+/P5WVlfZ4OqdOnWoXW6e74UIHOwPS5gwwzGcYvjpf9pfsByAkZAFlZf+lqamin1smkTgfjggZOmXKFN5//31A2aDjgw8+4LLLLuvzzzJQGLDiDMrE4Lt73gVAo9ERFvYA+fl/6d9GSSROQovNOS0tjVtvvbVdyNBZs2a1y9sSMvRsPPPMMxw9epTU1FRGjRpFTEwMd9xxR29+hAHNgIqtcToNlgbSlqWx/979uGhcsNka2blzNGlp3+Lqen6TGxLJ+SBja1y4yNgaDkCn1TE1ciprs9cCoFa7Eh7+MPn5S/q5ZRKJRHJ2BrQ4Q3ufZ4Dg4HmcOrUes7m4H1slkUgkZ2fAi/PY0LGcqD5BaZ2ytbta7UJ4+KPk57/czy2TSCSSMzPgxVmlUnFH8h18sO8D+72goDuorPwGs7mwH1smkUgkZ2bAizPAHSmKOLfMfarVWoYNe4K8vBf7uWUSiUTSOYNCnIM8gxjmM4yMoozWe0G3UVX1Aw0N+f3YMolEIumcQSHO0DwxuLt1YlCl0jB8+JPk5f2pH1slkfQfjg4ZCvDWW28xcuRIRo4cybhx4/jxxx/P2Y7PPvtMuhV2wqAR5xmxM/jm2Dc0WBrs9wIDb6amZhsm0/H+a5hE0k84OmToF198wZtvvsmPP/7IoUOHWLZsGb/4xS8oLj67Z5QU584ZNOLsonHhmthrWHNojf2eMnp+mry8F/qxZRJJ/+OIkKEvv/wyS5YsscfTGD16NPPmzeMf/1B2I4qIiOA3v/kN48aNY9y4cRw9epQtW7bw+eef8/jjj5OWlkZOTo7jP9wFyqARZ1C2sGrr8wwwdOhsamt3YzLJXwrJ4KJl+fbIkSNZsGABzzzzjP1ZZyFDz0VmZiZjxoxpd2/s2LFkZmbar729vdm+fTv3338/Dz/8MBMnTmTmzJksWbKEPXv2EB0d7bgPeIEzYKPSdUZKUAqnTKc4WXOScG8lVKFKpWbEiN9x4sTzjBz573OUIJH0PpN27aKyBxHb/LRafho9usv5HR0ytDOEEO3Cht522232469//etulzeY6LI4r1+/noceegir1cqCBQt48sknO823Y8cOLrroIj788ENuuukmhzXUUcxNnct7e9/j6Uuett8LCLievLw/UV+fjbt7bD+2TiKhWwLrKBwRMjQxMZGMjAymTp1qz7Nr1y4SExPt122FurP4z5JWumTWsFqtLFq0iHXr1pGVlcXKlSs7NeBbrVZ+85vfMH36dIc31FH8IvkXrDywkrbxnlQqFRERizly5B4sFmM/tk4i6R8cETL0iSee4De/+Q0VFUpY3j179vDuu+9y33332d/58MMP7ccJEyYA4OXlRW1tbV98zAuKLo2ct2/fTkxMDFFRUQDMmTOHNWvWtPuPCPD6669z4403smPHDse31EEM0Q8hISCBLflbmDR8kv2+v/81mM2F7Nt3JUlJn+PqOrQfWymR9D4tNmdQzA9tQ4auW7euXd6WkKHjx48/Y3kzZ86koKCAiRMnolKp8PLy4oMPPiAkJMSex2w2M378eGw2m32icc6cOdx999289tprfPLJJ9Lu3EyXxLmgoIBhw4bZr8PDw9m2bVuHPKtXr+bbb791anGG1mBIbcUZIDR0Aa6ugezdewVJSZ+h10f2Uwslkt7HarV2ev/YsWMd7v3tb3+zn0+ZMuWMZd57773ce++9Z3y+aNEinn22/V6ekyZNkq50ndAls0ZnIZ9Ptxc9/PDDvPzyy2g0Gse0rBeZFj2Nn/J/oq6xrsOzgICZxMX9P/bvvxajcW8/tE4ikUi6OHIODw8nP791mfPJkycJDQ1tl2fnzp3MmTMHgPLyctauXYtWq+WGG25ol89oNPLII48AyoRCf9inNWoNN8TfwKcHP2Vu6twOz318JmEwfERm5q3Exi7Fz29Kn7dRIhloHD9+vL+b4FA2bNjAhg0bAEXXHI7oAk1NTSIyMlLk5uYKs9ksUlJSxIEDB86Yf968eeLjjz/u9FlCQkJXqux1DpcfFpe9e9lZ85hMJ8SOHWmitPSTPmqVZLDgLH8Hku7T2c+uN36eXTJraLVali5dyvTp00lISOCWW27BYDCwbNkyli1b5vj/GH1AnH8cjdZGcitzz5hHpxtOaupG8vP/TkHBG33YOolEMtgZ0HsInou3d71NfnU+f7jsD2fNZ7XWk5V1K56eo4mIWCz9MyXnjTP9HUi6h9xDsA+4xXALnxz8BJuwnTWfRuOOwfBfzOY8jhxZiM3W/dVbEolE0h0GtTh7u3kzJmQMm45tOmdetdqF+Ph/4eLiT1bWzVitpj5ooUTSe1yIIUMXL17MX/7yly7lbcvOnTt58MEHu/1efzKoxRk6bgB7NlQqFVFRf8LXdwr79l1FU1NlL7dOIuk9BlPI0LFjx/Laa6/1ah2OZtCL86URl7K7eDfVDdXnztxMePhDhIbey969V2A2F/Ri6ySSvsGZQ4a+8MILxMfHc8UVV3D48OF2bbzqqqsYM2YMl1xyCYcOHQLg448/JikpidTUVCZPngy0H/GXlZVx5ZVXMnr0aO655x5GjBhBeXk5x48fJyEhgbvvvhuDwcC0adMwmfrxG7LD/T/OgTO6EC3etFi8ufPNbr9XUfG12LbNIIzGg73QKslAxhn+DtRqtUhNTRXx8fHC29tb7Ny50/7sj3/8o3juueeE1WoVI0aMECUlJUIIITZt2iRmzJjRaXl+fn6iqqqq3b3PPvtMzJo1SwghxIgRI8Tzzz8vhBBi+fLl9nLO5nq7c+dOkZSUJOrq6kR1dbWIjo4WS5YsEUIIMXXqVHHkyBEhhBA///yzuOwyxTU2KSlJnDx5UgghRGVlZYd2L1q0SPzpT38SQgixbt06AYiysjJx7NgxodFoxO7du4UQQtx8883i/fff79CmvnKlG1ghQ5ctg1/8Ary9u/XavLR53P7f2/m/Mf/XrfeGDLmChITlZGbeSHz8O/j4XNSt9yWSztg1aReWyu5POmv9tIz+aWCFDP3hhx+YNWsW7u7ugBK/A5RFH1u2bOHmm2+25zWbzYCyHPzOO+/klltuYfbs2R3K/PHHH+2mmquuuqrdN4bIyEh7vJExY8b068KZgSXOAI8/Dm++2a1XInwj0Gl1HCw7SMLQhG696+U1huTkzzlwYDbDhz9JUNBt3XpfIjmd7giso3CWkKH5+flcd911ACxcuPCM+Ww2G76+vvZ/Lm1ZtmwZ27Zt48svvyQtLa1DHnEW72E3Nzf7uUaj6VezxsCyOf/f/0FODmzc2O1X70q7i79s+ctZf3BnQq+PJi1tE6WlKzhyZBE2m7nbZUgk/YmzhAwdNmwYe/bsYc+ePSxcuJDJkyezevVqTCYTtbW1/O9//wOUHVUiIyP5+OOPAUVw9+5VYuHk5OQwfvx4nnvuOQICAtqFngC4+OKL+eijjwD46quvqKx0zon9gSXOajX885/w8MPQzfiwc5LmoFapmf/5fJqsTd2u2sVlCElJa3BzC2fPnik0NJw490sSST/SEjI0LS2NW2+9tV3I0FmzZrXL2xIy9GzMnDmT+fPnM3HiREaOHMndd999xpChr776Kn//+98BJWTokiVLGDVqVIcJwdGjR3PrrbeSlpbGjTfeyCWXXGJ/9p///Id33nmH1NRUDAYDa9Yo+4M+/vjjJCcnk5SUxOTJk0lNTW1X5rPPPstXX33F6NGjWbduHSEhIXh5eXW/A3sbh1uxz0GfTIS8/roQ993X7ddsNpt47rvnxLT3p4nqhuoeV3/q1Ldi27YEUV7+ZY/LkAxsnGFCsK8ZMWKEKCsr6+9miIaGBtHU1CSEEGLLli0iNTW1W+87VWyNC4777oOsLPjuu269plKpeObSZ7gt6TaueO8KCmsLe1S9n99lpKZuJC/vz+Tm/g4hOo+bK5FI+p68vDzS09NJTU3lwQcf5J///Gd/N6lTBt6EILSaN2bNgp9/Bg+Pbr1+Z9qdhHqFMu39aXx404cYAg3dboKbWyipqRs5duy37N07ncTE/+DqGtTtciSSgYKzhAyNjY1l9+7d/d2MczIwR84AMTGwYAE8/fS583bCtOhpfDD7A2755BY2H9/cozLUai3R0S8THv4Ae/ZMparqhx6VI5FIBh8DV5wBHngAdu+GH3omimnBaaz9xVp+veHXrDpw9smQsxEQcD3Jyf8jJ+cx8vJ65hEikUgGFwNbnNVqePttuP9+qK/vUREjfEfwzdxveDPjzR672gHo9VGkpW3GZMomM3M2TU1VPSpHIpEMDga2OAPExcHcufDMMz0uwk/vx/rb17OzcCcPrnsQq61nE3wajY74+DcJCJjFnj2Tqa11fruXRCLpHwa+OIPi9/zzz3BaSMTu4KZ1Y8WNK9C76Lnp45swNfV85VBw8FwSEv7DoUN3UVj4tjRzSPqNkpISfvGLXxAVFcWYMWOYMGECq1evpr6+nttvv93uL3zxxRfb98lrCTXakl566aV+/hQDk4HprXE6Go1i3rjtNti6FfT6HhWjVqn585V/Zun2pUz7YBqrb11NgHtAj8ry9Exm1KjvOXz4bqqrfyQu7v+h0bj3qCyJpCcIIbjhhhuYN28eK1asAODEiRN8/vnnvPrqqwQFBbF//34ADh8+jIuLC9A+Joek9xgcI2eAhARFnBcvPu+i7h93P49c9AiXv3c5Oac6hjjsKlqtN4mJq/DyGs2uXRdRXv65HEVL+oxvv/0WV1dXewwLgBEjRvDAAw9QVFREWFiY/X58fHy7uBOS3mfwiDPAo4/C99/Dtm3nXdSshFksm7GM61Zex46CHT0uR6VSER7+IElJn1NSsoJ9+6ZhNO4/7/ZJJOciMzOT0aM7D7I0f/58Xn75ZSZMmMDvfvc7srOz7c/aLvtOS0uzx8uQOJYBZdaoqgJf37Nk0GqVxSlz5yrmjfMcCUwYNoHP5nzGTR/dxJ8u/xPXxp15+55zoddHYDCsoqrqRw4fvhtPzzQiI5/D1TXwvNooufDYtWsSFkv3g/FotX6MHv1Tj+tdtGgRP/74I66uruzYsYPc3Fy++uorNm7cSHp6Olu3biUhIUGaNfqIASXODz8MY8Yo7s1nJCkJbrwRnnsOXnjhvOuM849j49yNzFw5k1pzLbcln1/IUF/fixk9egslJR+wZ88UgoPnEx7+AGq1/Eo5WDgfge0OBoOBTz/91H79j3/8g/LycsaOHQuAp6cns2fPZvbs2ajVatauXUtCQvdC6kp6zoAya7zxBqxZA2+9dY6MTzyhhBXNyHBIvYEegay/Yz2vbX+NjzI/Ou/yVCo1wcFzGT16O1ZrDRkZ6ZSVfSbt0RKHMnXqVBoaGnjjjTfs9+qb1wP89NNP9lCajY2NZGVlMWLEiH5p52Cly+K8fv164uPjiYmJ6dR1Zs2aNaSkpJCWlsbYsWO7tOuuo9HrFXFesQKWLz9LRhcXxbxxzz3Q2OiQun11vqz9xVr+uvWvfJr16blf6AJarSeRkc+RnPwFZWUfs3fvFRiNex1StkSiUqn47LPP2Lx5M5GRkYwbN4558+bx8ssvk5OTw6WXXkpycjKjRo1i7Nix3HjjjUBHm/OTTz7Zz59kgNKV0HUWi0VERUWJnJwcYTabRUpKisjMzGyXp7a2VthsNiGEEHv37hXx8fGdltUXoRJraoSYNEmIFSvOkXHxYiF+/3uH1l1eVy7GvjVWfHbwM4eWK4QQVVVbREbGBHHo0N3CbC52ePmSvmMwhgwdKDhVyNDt27cTExNDVFQUrq6uzJkzxx7YugVPT0/7djJ1dXWdbi3TV3h5wRdfwKuvwqdnG8Q+9RSsXQsOnNzwd/dn3e3r+OP3f+SLI184rFwAH58JjBr1I76+l7Jnz1Ty8l7Gam1waB0SicQ56JI4FxQUMGzYMPt1eHg4BQUFHfKtXr2akSNHMmPGDP71r385rpU9wNcXvvwSXnoJmne26Yirq2KgvvtuaOr+7idnIsA9gLW3r+X3m37Puux1DisXFHt0UNDtjBmzHZutgV270ikr+1TaoyWSAUaXxLmzP/zORsazZs3i0KFDfPbZZzxzHrEsHIW/vyLQzz4LGzacIdOoUXDVVfDiiw6tO9AjkHW3r+Ppb5/mq5yvHFo2gEbjQUTEsyQnr6Oi4kt27hxFQcEbWK11Dq9LIpH0PV1ypQsPD2+3SeLJkycJDQ09Y/7JkyeTk5NDeXk5AQHtlzcbjUYeeeQRQNm9d/r06T1pd5cJDFQE+qqrlHnANhsDt/K738HEiUpw/uRkh9Ud5BnE2l+s5er/XI1GpeHyqMsdVnYLOl04I0f+C7O5mMLCZWRkjGXIkBmEhd2PXh/h8PokEonChg0b2NA86muJO+JQumKYbmpqEpGRkSI3N9c+IXjgwIF2ebKzs+0TghkZGSI0NNR+3ZbenAhZWVwsKhsbO32Wny9EcrIQP/xwhpczMoRIShLi8GGHt+tk9UmR8kaK2HRsk8PLPh2rtUEUFb0ndu4cJ/bvv0GcOrWp05+DpH+RE4IXLn01IdilkbNWq2Xp0qVMnz4dq9XK/PnzMRgMLFu2DICFCxfy6aef8t577+Hi4oJer+fDDz/s80lBG3DF3r2sSU4m7LTVf+Hh8PnncO218M47MH78aS+PHg3/+pcyev73v2HcOIe1K8w7jC9u+4IZK2aw9JqlTB4x2WFln45a7UZw8C8JCrqDmpqtnDz5Gjk5jxIaei9BQbej0fQs6JPEsQQGBpKYmNjfzZD0gMDAvlm1qxKib2eSEhMTycrK6rXyvz51il8fPconBgMjO9k78OhRuOEGeO89RY87kJ0Ns2fDn/8MV1/t0LadqDrBtSuvZdmMZUwaPsmhZZ+NhoaTFBa+QVnZpwwdOovQ0PvQ6Yad+0WJRNIlekPXBtQKQYArhwxheUICN2Zm8nN1dYfnMTHwySfwy1/C/s7iC8XGwtdfK7OI773n0LaN8B3B53M+554v7mFr/laHln02dLpwoqJeYOzY3ej1sRw4MIvMzFuorv5JenlIJE7KgBNngDFeXnyenMz/HTnCF+XlHZ6PHAkffghz5sDBg50UEBysLO9+7z1YsgQcKGCRfpGsmbOGBf9bwPaC7Q4rtytoNHpCQuYzZswOwsIWkZ//V3btGk9Bwf+jru6gFGqJxIkYcGaNtpQ0NnL9/v38X2go80NCOjzfvRvuuAM++0wZMHfAbFYi2IWFwV/+ouxJ6CCyK7K54cMbeO+G9xgTOsZh5XYXk+k4ZWUfU139PfX1R/DwSMbX91J8fSfj4ZGMSjUg/39LJA6lN3RtQIszQK3Fwk2ZmUz29eXp4cM7TFJu3w7z5ysLVSIjOynAZlPC3ZWXw7vvKgtXHMTh8sPM/mg2H8z6gFEhoxxWbk8RworRuJ/q6s1UVX1PXd0B3N3j8fGZjK/vpXh6jkKtHlCBDCUShyDFuYc02mzMP3QIX62WV2Nj0Zwm0D/9BAsXKv7Qw4d3UoAQylLDTZuU9eBeXg5rW1ZZFjd9dBPLb1hOeli6w8p1BEII6usPUlX1PdXVm6mt3YVOF4Gv76X4+EzG2ztdhjKVSJDifF7YhOCJnBxOmM28P3IkOo2m3fPvvoP77oOHHoIFC5RtBzvw7rtKXNLPP4egIIe1LbM0k/vX3U+jtZF5qfO4xXALvjpfh5XvKIQQmEw5VFd/T1XV99TWbsfVNZjg4HkEBs6RQi0ZtEhxdgB/zc/ny4oK/msw4Nu8YWULlZXKFoM//wx//7uyaLADX34JTz8N//0vREc7tG3HKo/x/r73+SjzI5KDkrkz9U6uiLoCjbqz/xTOgcmUQ2HhMioqviAw8DZCQxfK3Vskgw4pzg7iPyUl/D0/n8+TkwntZKuq/fuVEXRYGLz8MnRYqf7zz/CrX8H775/BWfr8sAkbP+b9yPI9y9lycgvXx1/PvNR5JAx13l0oLBYjxcXvUlT0Jl5e4wgPfxhPT8cthZdInBkpzg7k61OneCQnh48TEztdrCKE4g+9eDHMm6fMCbabCzx4EG6+GV55Ba64otfaWddYx38P/pfle5dT11TH3JS5zEmag5/er9fqPB+EsFFR8SUnT74CqBg27NcMGXK19PqQDGjkIhQHcuWQIbw7cuQZF6uoVIr2bt8ORiOkp8O6ttE/ExKUUHdPPgkrV/ZaOz1cPfhl6i/ZOHcjH970IadMp5j87mRu+fgW1mavxWKz9FrdPUGlUhMQcB1pad8QE/NXyso+YefONAoK/p+MmCeRdINBO3JuIcdkYtaBA7wYFcUMf/8z5svNhUcfBatVsUfbzc1VVcp68Ouvh1//ui+ajBCCLflbWL53Od+f+J6Z8TO5L/0+Inwj+qT+7tLYWEJBwRuUlq4iIOB6wsLul8vHJQMKadboJVoWq9wZHMw9oaFnDdj01VfK/rAzZijzgh4eQEOD4izd1AT/+IcSp7SPMDWZ+PTgp7y67VVih8TyxKQnSAtO67P6u4PV2kBp6UoKCpai18cSHv4wPj4X9XezJJLzRorzOSh+r5iA6wPQ+nR/oUStxcKi7GxqrVbeiotj6FkWmzQ2wuuvK0Hsfv97uOUWxQzCxx8rMTmeeUZZG96HUfmEEHyd+zV//unPaNQanpj4BFMjp/brdmFnQghBVdUmTp58BZMpG50uEp0uojm1nru4BDhl+yWS05HifA5K/lNC4VuFpKxLQePeM/ezD0tL+cPx4/w1Opqrz2LmACgqUrYhPHFC2a8wJQUoK4MHHlBG02+8AZ0sG+9tdhbuZMmWJRyvOs6jEx7lxoQbndYdz2Zrwmw+SUPDMRoajrdJx2hqKkelcsHNbbhdsPX6VvHWaodI8ZY4BVKcu0DB/yug4n8VJK1JQu3as/nOkw0N3HX4MPF6PX+Ojsa90xUprWzdCo8/riwcnDtXMUHr16+G3/5WUe877ujTUXQLR08d5W9b/8YPeT9w39j7uDPtTvQuF1Y8Z5utEbM5H5Opc/HW6Ubg63sZvr6X4eU1BrXa5dyFSiQORopzFznx4gmMu40krkxEpemZKNqE4NWTJ3mvpIR34uMZ3YUl2/v2Ka7P//sfXHwxzL++ggkfPoyqqhLefFNxnO4HSutKeX3b63yc9TF3pNzBfen3MUQ/pF/a4kiEEDQ05FJZuYmqqk3U1mag10e1EetRqFTO+Y1BMrCQ4txFhBDkPpmL5ZSFuLfizuur736jkbsOHeLGoUN5YvjwDnE5OsNigW++USKO7tkDTyV/wc0Zv8HtqUfhrrv6ZRQNYGw08vaut3kr4y2mR0/n1xN+zXCfzoKJXJgoy8uP2MXaaNyDu3ucXaw9PVOlv7WkV5Di3A2EEBxZeASNl4boJdHnJdBmm43fHTvG9poa3h05kkh9100DNTVKrKRP36liYfYjpAQU4r3yLXxT+k8Um6xNrDqwir///HcMgQYeGv8QY0LGDDj7rRK4Kcsu1nV1+/HwMNjF2sPDIMVa4hCkOHcTYRVk3Z6FZ7InI3474rzL+7aykgeys3li+HDmBgV1W8yOH4ctz64n/cPH+DbxAUKe/T+uvkaFSz+ZSYUQrD+6nmUZy8g5lcPM+JncnHgzacFpA06oQVm9WFe33y7W9fUH0elG4OU11p7c3DqGlZVIzoUU5x5ga7RxYNYBhlw9hPD7w8+7vMqmJu7LzsYiBMvi4vDvgbKK6hpK5z1O5c4cFrn+E8O1kcybp4Tp6C9dqG6o5n9H/sfHWR+TW5nLzLiZ3Gy4mdSg1AErVorN+gS1tTuprd2J0ZhBQ0Meen0Unp5j2gh22IDtA4ljkOLcQ6z1VvZds4+Q+SEEzw12SJkrSkp44cQJXomJ4cohPZxc27gR20MPs2/ivSwuuZcT+Wpuuw1uv73f5g6BVqH+KPMjjlUdY2bcTG4x3EJKUMqAF6mWScYWwa6tzcBsLkCvj20W6zHNgt33LpIS50WK83lgqbGwd9pehj85nKE3DHVImXkNDdx56BApHh68GBWF/hwud51SW6vE5/jxR+ovnsbX4gr+uv0S9P7uzJ0Ls2aBu7tDmtsjqhuq+fzw53yU9REnqk4wM14R6uTA5AEv1C0IYcNkOmoX69ranTQ2FuPqGoiraxhubuG4uYU1J+Xc1TVUuvUNIqQ4nyeN5Y3su3If0X+Jxu9yx0R1swrB3/LzWVVayuuxsUz08elZQZWVSsT/jRvh+++p0wfwg+4K/pV3Jd6XjeGXd2q45BKHbmPYbaoaqhShzvyIvOo8ro+/npsNNw8qoW5BCIHFcgqz+SRmc0GHY2NjIUI0oVZ7tBPtlqNeHyPt2wOIfhXn9evX89BDD2G1WlmwYAFPPvlku+f/+c9/ePnllwHw9PTkjTfeIDU1tUM5/R1bw1xgZt9V+4j7Zxw+F/VQSDvhgNHIA0ePMsLNjZejowk6370GT5yAb77B9vVGTD9kkKUysN5yBd6zr2DGw7HExPbvH3VVQxVrDq3h04OfcrjiMIEegaQFpZEanEpacBqGoYYLbsFLb2C11nUi3ieprz+M2ZyPh0cyPj6T8PGZ2LxHo+P2qJT0Hf0mzlarlbi4OL7++mvCw8NJT09n5cqVJCYm2vNs2bKFhIQE/Pz8WLduHYsXL2bbtm198iG6S/3Reg5cf4DEVYl4Jns6rFwhBKtKS/njiRMsDA3lvtBQtI4Y6tpscOAADf/7mvJVG7HmHueA5wR0113J2Cem4hPnuC2zekqxsZi9xXvZW7KXPcV7yCzLBCApMInUIEWwU4NSCfLs/7Y6Czabhbq6A9TUbKG6egtG4y5cXPzx9p6Ij89EvL0nyF1lLhD6TZy3bt3K4sWL2bBhAwAvvvgiAE899VSn+SsrK0lKSqKgoKDDM2cQZwDjfiNZc7JIWpOEe4xjjbq1FgvPnTjBpspK/hYTw2RfX4eWj9lM4X9/5uiyjXjv+AZvnZmC2x4n5re3EhLqPF+TTU0mMssy2VO8hz3Fe9hbspfSulKi/KLaCXasfyxauas3AGZzETU1W6mu3kJNzRYslhq8vMY2i/VEPDwSpW+2E9Ibutalv4iCggKGDWuNvxseHt7pqLiFd955h6uvvvr8W9eLeCZ7Ev9OPJmzMklel4wuXOewsr20WpZER5NVV8eD2dkEu7qyJDqakE62xOoRbm6E3nYpobddihB/JOOLIjyfeZqihGU8FPwqoVencuWVMHmyQzcK7zZ6Fz1jQ8cyNnSs/Z5N2DhedVwR6+K9rDywkuyKbNxd3EkOSiYlMIWUICUN9XDMxO2FhJtbCEOHzmbo0NmAEmbVaMygunoLx48/Q11dFjpdJH5+U/HzuwJPzzQp1gOULolzZ4PrM01kbNq0iXfeeYcff/zx/FrWB/hc5EPMKzEcuO4AKV+l4DrUsfa+RA8Pvk5N5ZOyMq7Yu5dfhYTwQFgYLg6c1VOpYOx1IXDdv2HbNlY8sJD8I6N4s+6PPP20P97eyi5aV1wB48bRbwteWlCr1ET5RRHlF8XshNn2+zXmGg6UHmBfyT4+Pfgpz373LGX1ZUT4RrQT7JEBI3HTDp5dvjUaXbNNehLQskT9KFVVm8jLexGjcR+enqn4+V2Bn98V6PVR/dxiiaNwqFlj3759zJo1i3Xr1hEXF9dpWcOHD+emm24CYPr06UyfPv28PoAjKPusjLyX8kjdkNqjWNBdwWix8EJeHhtOneKv0dFc5tdLewDabLB8OSxZAvffT8G19/DNdxq+/lrZcis+vlWsExL6b9FLVxBCcKL6BPtK9tnTofJDqFVqDIEGUgJTSA9LZ1zYODxdHTd3cCEhhBWjcQ+VlRuprNyI2VyIj8/FzWI9FReXs4e9lfScDRs22DXxk08+IS8vz6Hld0mcLRYLcXFxfPPNN4SFhZGens6KFSswGAz2PHl5eUydOpX33nuPiRMnnrEsZ7E5n07x+8Xk/yWfEc+MYOjsoajUvaNah+vreTA7Gz+tlr9ERxOuc5w5pR3V1fCHP8APP8Bf/wqTJyMEZGUp3nobN8KRIzB+vGL+SEqCxETw9u6d5jgSU5OJrLIs9hTvYVvBNnYU7kCtUjM+bDwTwicwYdgEov3OL57KhYrVaqK6+icqKzdSVfUtIPD1VUwgPj4Xo9FID5reoF9d6dauXcvDDz+M1Wpl/vz5/Pa3v2XZsmUALFy4kAULFvDpp58yYoQSw0Kr1bJz584O5TirOAOYjps48ccT1O2rY8QzI/C/zr9X/sCFEKwuL+eZY8eYFxzMw+HhuPaWA3NWlrJ1uL8//PnP0GbuoKkJtm2DLVsgM1NJdXUQGamItcGgHBMS+nchTFeobqhme8F2tp7cytaTW8mtzCXeP54J4ROYOGwiY0PH4uHacZf1gU5TUwWVlZuorPya6uofcXUNwcdnEnp9NDpdFHp9FK6uwdJufZ7IRSh9RH12PSeeO4HpqIkRz45gyPTe2XGj3mrlxbw8/ldezlMjRjDNzw+/3jAKCwFr1rRun/Xoo3CGEbvVqgRoOnCgVbCzspStuWJiFMFuEe34+DMW0+/YhI3D5YcVsc7fyo7CHbhoXNqNriN9Iwfd6NpkyqWmZjsNDbk0NBzDZMqlsbEQ0KDTjUCvj0Kni0Kni2w+j0Sr7cdZ5QsEKc59TN3BOo4vPk5jYSMRz0Xgd1nv2ImP1tezrLCQ76qq0KpUTPXz4wo/PyZ6e6PryZLwM2EyKSaODz+E55+HmTO7bHS2WCAnp71oHzqkmLgNBhgzRkmjRkFvmdPPl6qGKrad3GYfXZ+oOsEQ/RDiA+KJ929OAfHEDInBVTO4FoMo24XlNe84k4vJlGsXcKvViEbj07xFWFTz8vTg5hSCq2twr5tLhBBYrXVoNB5O+Q9VinM/Ydxr5Nizx7DWWol8LhKfSY5bWXg6ZY2NfFtVxTeVlfxUXU2omxuX+/pyhZ8fo7y8uhTs/5zk5yv7alVWwiuvKHaLHtLYqAj2rl2QkaEcjcZWwR49Wjn2NDZUb3PKdIrD5Yc5XHGYQ+WHOFxxmJxTOdiEjQjfCLtgtxyDPLofKnYg0NRU1bzPYy5mcxGNjUU0NhY3pyJsNhOgxsVlKK6uwbi5hXQQcEXEPbBYqmhqOoXFUmk/tj8/RVOTcs9qrW1ugQq1Wo/VasTTM7l5oc6k5lWV/R/DRIpzP1Ozs4bjvz+OsAki/xiJd3rvz57lmkx8U1nJxspK9hiNJHl4cEXzyDpGrz8/odi8WTFxREYqtuihQyEwUEltzz08uuXW0dSkjKxbxHrXLmV+MjGxVazHjIGAgJ43vbex2CwcrzpuF+7D5Yc5VHGIEmMJ3m7ejAwYyaUjLuXq2KsJ9Qrt7+Y6BUJYaWoqbyPaxc1C3iriVqsRF5chaLV+aLVDcHFRjlqtn/1+2+enj5QV75T91NT81LyqcjcuLkPt7obe3hNwcen7kYAUZyehems1x39/HLVeTcRzEXil9Y1NziYE+4xGNjaL9QmzmQne3lzu50eShwfROh2e2m66AlossHcvlJYqO4eXlnY8NxqVvJ6enQt4bKwy+j6LPaOpCQ4ebB1hZ2QoA/dhwxQPEU/PjsnL6+z3PTzAkVafrlLdUE1WWRbfHPuGdUfX0WBpYFrUNK6JvYYJwybI1Y59jNlcQHX1Fqqrf6KmZgs2mxlv73H20bVeH3tegxghBEI0olK5nHHiVIqzk1G1uYpjvz+Ga6ArEYsj8DD0rTeA2Wbj55oavq2s5FB9PbkNDdRaLAxxcSFarydap1OOzSnQxeX8Rtp1dR3Fu6QEsrOVWcPKSggPV4bILSkhQRHxTuq1WKCwUNH+zlJt7dmf1dYqE5gjRijVjBzZmoKC+s6H+5TpFF/lfMXa7LVsK9hGalAqV8dczVUxVxHiJeM+9zVWax01NTvso2uT6Sju7iNxd4/HZmvEZjNhszV0OFqtyhHaSqJyrla7kZKyHlfXzmPDSHF2QoQQVG6s5MRzJ9D6agl7MAy/K/z61S55qqmJHJNJSQ0N9vOSxkZ0ajWRpwl3iocHwY5YWi4EFBQoQn3woHLMylJEPCioVaxbhDs09LwV1GaDvDxlcrJtKikBX9/2gj1yJERF9e4qSZuwkVGYwbqj61h3dB0Wm4Xp0dO5JvYaxoeNR6OWu4H3NULYqK8/iMmUg1qtQ63WtztqNG2v3Xq0Y7sUZyenZnsNBa8XYNxvJPTuUILmBqH1cq6vuCarleMtgt18/LmmBl+tll8GBTErIKD7ppFzIYQi0G0FOytLGTb7+bX3zzMYICTEIcPeysqOop2bqxQdE6P8n2ipurfcAsvry+2j6h2FOxgVPIprYq9h0rBJBLgH4O3mPSgnGAcaUpwvEMzFZoreKqJ0ZSl+0/0Iuz/M4ZHvHE1WXR3vl5SwprycMV5e/DIoiMv9/BzjHXI2Tp1SZg/b+ugVFiq27LaCbTAo9xxAY6PiFpiV1Vr14cPKKDwurn21sbFwvqG5W7DarOws3Mm6o+vYUbiDU6ZT1JhrEEKgUqnw1fnir/dniH5I69G982t3F3fUcuGI0yDF+QLD1mij7NMyCpYWKCaPB8IYMm1Iry0NdwQ2IdhcVcX7JSVsqa7mWn9/fhkcTKpnH8euKC1tL9gHDih27tDQVvVMSlLcPxy0fLGxUVnS3rbKI0eU3WfajrKTkiA6Ghz5BcMmbFQ1VHHKdIqK+grlaKro9PqU6RT1TfUIRLugZCqVCo1Kg06rsyc3rVvrtUY5+rv7YxhqwBBoIHZILC6a/ndFu9CR4nwBU7Oz2eSxx0jIghCC5wWj9XYuk8fp1FutfF5ezvslJRQ1NnJbYCC/CAoizFGhT7uLEFBU1Cra+/fDjh2Ku8ellypp0iTFlcOBNDQoJpG2A/ycHEWcY2Nb7dnx8Urqz/gkFpsFs8VMg6Wh02S2mimtKyWzNJMDZQfIrshGq9aSODSRpMAke4rwjZAj824gxXkA0FjaSNE/iyj5oAS/K5tNHnHObfIAKGlsZFVpKStKSvButk/P7g37dE8oKoLvv1f8trdsUYzHkycr6eKLlZnBXsBkgqNHFeE+fLj1WFurDPDbivbIkYrbYH/uAXkm6pvqOVR+iAOlB+zpWNUxvFy9MAQaSBraKtqhXqH9YiMXQlBkLCLAPcApV29KcR5A2JpslK8up2BpARoPDcG/CsbvMj9c/J3/K+bBZvv0Z+XlpHl6kujujr+LS2vSau3n7v3hiFxWpkTj27wZfvxRmQG85BJlZH3JJUoQqF5ECMVs3la0Dx1SFmbqdIpYR0Yqc6G+vh2PLam//+9VN1STWZbJgdID9pF2QU0BAe4BGIYaSApMwhBowDDUQKBHoMNE22wxk1mWyd7ivfYddIqMRYR6hVJaV4qXqxdjQ8cyLmwc6aHpxAfE9/soX4rzAKV2dy2lK0qp2lyFsAp8J/vie5kvPpN9cPF1XrG2CcHPNTUca2igoqmpNVks9nOTzQaAi0rVqXgPdXEh2NWVIFdXgl1dCXBxQe3okdmpU4pIb96siHZjozKinjixd101OqGuTrFjnzgBVVWKR0lVVcfzqirFD1ylUhbanC7i/v6t64DaJj+/3h+dl9WVtRPtzLJMSupKCPEMsduykwKTMAw14O9+9n+EZXVl9n0n95bsZX/JfmzCRuLQRPs2ZmnBaQR7BtvFv6K+gp2FO9lRuIPtBds5UnGEUK9Q0kOV2N7pYekM8x7WpyN8Kc6DgKaqJqq/r6ZqUxVV31eh0qjwvbRZrC/xcTrXvK7SaLO1E+9TzedlTU2UNDZS3JzKm5qwATq12i7YLSmoWchbko9W27M/wOpq+OknJV5qVpYyvLVaFQNyYqIi2ImJimg7QazUpialyS0CXlkJ5eXKF4S2qbRUeSaEMuoOCOgo3kOHKp6KERGK6cVRQi6EoNhY3EG0K0wVDPMeZhdtbzdv9pXsY2/JXo6eOkqAe0C7/SSTApO6HdpVCEFBbQHbC7azo2AHOwp3kF+TT5x/HOmh6UoKSyfAvffiBUhxHoQ0VTRRtbmKqk1VVP9YjVqnxndKs1hP8kHjMTAXNTRYrZQ0NdlFu7ixsZ2IFzc2UmWx4KZWk+ThQbKHBykeHiR7ehLq6tp90W5qUgzILTFSs7IUW0RLrNSWhTMGg2JA9nDu2NBNTVBR0SrabUW8sFAJC1tUpOQND1fMLBERyrElBQScv7u5EIKTNSftol1jriElKIXUoFSih0T3mjnCJmxkV2Qrgl2oCHalqRIfnQ9hXmFK8u547OmOOlKcJTSWNlL1XbNY/1SNxluD32V+eI3zwjPNE7dwt0G1qKHOaiWzro79dXXsNxrZV1dHodlMsKsryZ6eimB7eJDk4dGzycuWWKktTtEtqx8bGpSRdkpKa4qN7Z9gH+dByxL6Y8da0/HjyrGsTPHxHj68vXBHRSmuhH3tXekIasw1FNQUUFBb0PFYW4Cx0YhGpSHYM7hVtJuFe3r0dPQunYdGleIs6YC50EzV5ipqM2ox7jFizjfjFu6GZ5qnPbmPdEft4oRuAr2EEILixkb219Wxz2hkf10dB+rqaLDZiHN3J7llpO3pSbROh7Yn3+0tFmWkvW9fa8rOVhSrrWAnJzt3+L1z0NioLI9vK965uUqqrVVCwUZHt09RUX0b28TRWGwWio3FHcT7qYufwkfXebhgKc6ScyKEwFxgxrjHaE/1B+tR69XtBNszxdPp/awdTZPNRrbJ1E60j5pM6NVqDM2j65ZRdrhbD7+BVFcrztBtRbuiQhlythXtyEglyIdWqxh+L1AlO3VK+WLRknJzlWNJCbi5KR+zrXDHxiqBqpzRpfB8kOIs6TGWGgvGfc2CvduIca8Rm8mGe4I7nimeeBg8cDe4o4/Ro9YOsL+cc2C0WMisr+dAs2nkQF0d+WYzQ11cFMH29LQL95CeRE2y2RT3jLaCffy4MglpsSgJFIFu+XM8/byFltm+2Fhl25mW5KB4JI6koUEZabcV7xZPFS+v1hWXLasuw8Md8xEsFqV7jxxRvsy0HCsrIThYmQgNCWk9tpwHBvbcfVGKs8Sh2Jps1B+qp25fHXWZSjIdNaFyUeE+0h0Pg4c96aJ1g060Sxsb7fbsA83HU01NjNDpSPbwIM7dnVi9nji9nlA3N8e7AJ6JpiZlsnL37tZUVKQMU1vEevRoxb7gpEPUqqpWM37LysuTJxVXwLbhVJKSFEE9vWttNiUAYlsBPnJEEWVQbOSxsUqslJajnx8UFytdVVSk2NrbnpeWKsKu13cu3tOmKc86Q4qzpE+wmqyKaGfWUZ9Z3yrario8EpQRtkfi4BRtIQQnGho4UFfHEZOJbJOJ7Pp6ChsbcVWpiNbridXriW0W7li9nuCeeI90v2HKMHXXrlbBzs1VhoNtR9iJiZ3HTBVCUSazuTU1Nra/NpuVPLGxEBbWKx+joqJVsFtEu6hI+RgjR7aaUcxmZaTdVnxjYxVRPt+QsCZT5wL+1FNnXpovxVnSr1jrW0W7RbhNOcpIWx+jxz3eXUkj3dHH6516AU1v0GC1ktPQQHZ9vSLazam4sRG9Wk1Mi3Dr9QzX6fDRavHSaPDWaPDWatGr1Y4X8eLi9iPsrCxl2NlZPVqtYig+Pbm6tp5rNMqovahIiQaVnt6aenFn39JSpdqWCcgzjWD7CynOEqfE2mDFdNSE6bCJ+sP11B+qp/5wPZYqC65BrrjHK2LtPlIRb13k4BptgxJE6mizWB81mchvaKDGaqXGYqHWaqXGaqXOagVABahVKrtwe2m1dgH30mjw0WoJd3MjUqcjUqcj4Hx3uOkJVquiljt2tKb6ekhNbRXrUaOcYhFPX9Cv4rx+/XoeeughrFYrCxYs4Mknn2z3/NChQ9x1113s2rWLF154gccee6zTcqQ4Dx6EEDSVNimC3ZxMh02YjplQqVToonXoI/Vo/bW4DHFBO6TjUeutdeoQq72FxWbD2Czatc0i3iLm1RYL+WYzxxoayDWZqLBYcFOpGKHTEaXX20U7Sq8nQqfDo698r81mZT/KFrHevVsZaY8d2yrYUVHKGvaWPcha9htre36mZ3V1io/e6b57ERGOC7rdQ/pNnK1WK3FxcXz99deEh4eTnp7OypUrSUxMtOcpLS3lxIkTfPbZZ/j5+UlxlpwVW6MNU46JhhMNWE5ZaDrV1OnRUm2xb+mm8dK0F29/LboROvQxevQxelyD+8C266Q0NO9wc6w55ZpM9vM6q5UhLi520R7q4kKjEJhtNvvRntpcd/bMIgQGd3cu9fVlsq8vie7uZ+/zmhplN98WwT5xonWX3padelvOT78+/dzdXTHTtPjrtaTjx5VJ0pCQjsIdHQ0+nfsmO5Le0LUuOY5s376dmJgYoqKiAJgzZw5r1qxpJ86BgYEEBgby5ZdfOrSBkoGJ2lWNR4IHHgldWwYthMBaa20n3k3lTZhPmKnZUoPpqAlzkRm1To0+Wm8X7JbkFuY2oEfgOo2GkR4ejDzDsvLKpqZ2I21flQo3tdqeXNten+WZGthrNPJ9dTVP5+ZyqL4eg4cHk318uNTXlxRPz/a753h7w2WXKek8qLVYON7QgM+IEYTGxnZcOGSzKcLdItj79sHq1cp5dbXSjuHDlYhRQ4acPTmJQbtL4lxQUMCwYcPs1+Hh4Wzbtq3XGiWRnI5KpULrrZg5iDhzPqvJSkNug2IDzzFR9nGZItwnzag0KnSRbUbaoa6otCpUmubUfI6G1nvN9zvcc1HhGup6wdjO/Vxc8HNxYbSX13mXNdbbm7He3jwybBg2IThQV8f3VVW8mJfHPqORGL2eyb6+TPbxYYyXFy5dcOcTQlDR1MTR5r0tjzZvSnzUZKKiqQkvjYYInY5aq5UCsxmLEPi7uDDMzY3hOl3rMS2N4ePH43+6Hb66WvHVO3WqfcrN7XjPZFLe0Wjai/aSJcqxj+iSOHdm+RisXx8lzo1Gr7H7Zp+OrdFGw/Fm4T5qonZbLcIqWpNFgJV297CCsIgO92yNNswFZtQuatwT3O2LeDwMHuij9IrIDwLUKhUpnp6keHpyf3g4QgiOmExsrqpiaUEBGUYj4W5u9pF1hE7HsdPEN8dkos5qJcDFhWi93u7VcvWQIUTr9QzpJPqgEIJKi4W8hgbyzWbyzGa2VFcr5w0NVFgsqIFQNzdFuN3cCPT1xcXPD21MDFqVCheVCm2b5KJWt56rVGitVrRGI9qaGlyqq4nR6+lL/6MuiXN4eDj5+fn265MnTxIaGtqjCo1GI4888ggA06dPZ/r06T0qRyLpLmpXNe5x7g7decbuXnigjpqtNRS9XURDbgNqvVrxBU9qFW3dCN2ANq2AMmiLd3cn3t2d/wsNRQjB8YYGvq+uZnlxMXlmM1E6HTF6PWO9vJgTGEiUTtftoFQqlYohLi4McXEh7QzfBiw2G8WNjeQ1C3ZZUxNmmw2LEDQ128/bpk7v2WxYVCosPj4s02hoGyVlw4YNbNiwAVB0zdF0aULQYrEQFxfHN998Q1hYGOnp6axYsQKDwdAh7+LFi/H09JQTgpJBjaXWQn1Wq0943YE6Gk40oPXWKiP7pNbkGjp4JzIHCv02IajValm6dCnTp0/HarUyf/58DAYDy5YtA2DhwoUUFxczduxYampqUKvVvPLKK2RlZeHdn7tdSiT9hNZLi/d4b7zHt//9b6pqUlZdHqij4ssK8l7Ow3zSjEugSzvB9kjywDXA+fbKk/QdchGKROIENJY22kfYLampvAm3YW6KWLeMtg0egy6a4IVAv42cJRJJ7+Ia6IproCt+l7UugRZCYD5ptot14ZuF1GfWY6m1KJ4l2lYPk3Odo8F+rtapz7jop+Wo0V1YmwYMRKQ4SyROikqlQjdMh26YDv+r22+UKmytHiZ2bxJLG4+TTu63nNtMNiyVrQt9TDmmDguAbA3Kxrwqjaq9ePu5gAawKV4t2JS2dHq0ig73NB4a5RtAigceydJ0czakOEskFyAqtUrx/Ohl3y5bkw1LlaWdeAubUOpWK+KNmtbr048aVbt7lmoLdfvrKP2wlLrf1tFU0YQuQqfEFE9uFu0ED9Rufec/bmu0YamxYK2xYqluPra5bjkf/pvhaH36TjKlOEskkjOidlHjOtQV16GOG+H6Tva1nwuboOFEA3X76zDuM1LxZQX1B+sBcE90t4u2Z4onbsOV3WmEENjqbVhqLViNVqy1bZLRqtxvPu9wv1oRXpvJpkSYEqBybV7g5KNF461B6918bL52C3VDM1KDyrVvPWqkOEskkn5DpVahj9Sjj9QTMLPVi9jaYKX+oLIRRNXmKgpeL8Ccb1YEVQUadw0aTw0ar+bUfK710tqvXYNd7ect91sEV63rhfCsDkaKs0QicTo0Og1eo7zwGnX+y80vVC6MwAASiUQyyJDiLJFIJE6IFGeJRCJxQqQ4SyQSiRMixVkikUicECnOEolE4oRIcZZIJBInRIqzRCKROCFSnCUSicQJkeIskUgkTogUZ4lEInFCpDhLJBKJEyLFWSKRSJwQKc4SiUTihEhxlkgkEidEirNEIpE4IVKcJRKJxAnpsjivX7+e+Ph4YmJieOmllzo8F0Lw4IMPEhMTQ0pKCrt27XJoQyUSiWQw0SVxtlqtLFq0iHXr1pGVlcXKlSvJyspql2fdunVkZ2eTnZ3NW2+9xb333tsrDZZIJJLBQJfEefv27cTExBAVFYWrqytz5sxhzZo17fKsWbOGuXPnolKpuOiii6iqqqKoqKhDWUaj0TEtH2Rs2LChv5twwSH7rGfIfus+vaFrXRLngoIChg0bZr8ODw+noKCg23kA6urqetrWQY38g+k+ss96huy37tMbutYlcRZCdLh3+rbiXckjkUgkkq6h7Uqm8PBw8vPz7dcnT54kNDS023lAGf77+/sD4OHhgaenZ48aPtgwGo2sX7++v5txQSH7rGfIfusaRqPRPmLuDbNGl8Q5PT2d7Oxsjh07RlhYGKtWrWLFihXt8sycOZOlS5cyZ84ctm3bho+PDyEhIR3KMpvNjmm5RCKRDGC6JM5arZalS5cyffp0rFYr8+fPx2AwsGzZMgAWLlzINddcw9q1a4mJicHd3Z1///vfvdpwiUQiGcioRGfGYolEIpH0K326QvBcC1kGMxERESQnJ5OWlsbYsWMBOHXqFFdeeSWxsbFceeWVVFZW2vO/+OKLxMTEEB8fP6hm1+fPn09gYCBJSUn2ez3pp4yMDJKTk4mJieHBBx/sdEJ7oNBZny1evJiwsDDS0tJIS0tj7dq19meyzyA/P5/LLruMhIQEDAYDr776KtDHv2uij7BYLCIqKkrk5OQIs9ksUlJSRGZmZl9V7/SMGDFClJWVtbv3+OOPixdffFEIIcSLL74onnjiCSGEEJmZmSIlJUU0NDSI3NxcERUVJSwWS5+3uT/YvHmzyMjIEAaDwX6vJ/2Unp4utmzZImw2m7jqqqvE2rVr+/7D9BGd9dmzzz4rlixZ0iGv7DOFwsJCkZGRIYQQoqamRsTGxorMzMw+/V3rs5FzVxaySNqzZs0a5s2bB8C8efP47LPP7PfnzJmDm5sbkZGRxMTEsH379n5sad8xefJkhgwZ0u5ed/upqKiImpoaJkyYgEqlYu7cufZ3BiKd9dmZkH2mEBISwujRowHw8vIiISGBgoKCPv1d6zNx7uoilcGKSqVi2rRpjBkzhrfeeguAkpISu8dLSEgIpaWlgOzL0+luPxUUFBAeHt7h/mBj6dKlpKSkMH/+fPvXc9lnHTl+/Di7d+9m/Pjxffq71mfiLOQilbPy008/sWvXLtatW8c//vEPvv/++zPmlX3ZNc7UT7L/4N577yUnJ4c9e/YQEhLCo48+Csg+Ox2j0ciNN97IK6+8gre39xnz9Ua/9Zk4d3WRymClpS8CAwOZNWsW27dvJygoyB6fpKioiMDAQED25el0t5/Cw8M5efJkh/uDiaCgIDQaDWq1mrvvvttuFpN91kpTUxM33ngjt99+O7Nnzwb69netz8S57UKWxsZGVq1axcyZM/uqeqemrq6O2tpa+/lXX31FUlISM2fOZPny5QAsX76c66+/HlAW/KxatQqz2cyxY8fIzs5m3Lhx/db+/qa7/RQSEoKXlxc///wzQgjee+89+zuDhbZByVavXm335JB9piCE4Fe/+hUJCQk88sgj9vt9+rvmoMnNLvHll1+K2NhYERUVJZ5//vm+rNqpycnJESkpKSIlJUUkJiba+6a8vFxMnTpVxMTEiKlTp4qKigr7O88//7yIiooScXFxA3rW/HTmzJkjgoODhVarFWFhYeLtt9/uUT/t2LFDGAwGERUVJRYtWiRsNlt/fJw+obM+u+OOO0RSUpJITk4W1113nSgsLLTnl30mxA8//CAAkZycLFJTU0Vqaqr48ssv+/R3TS5CkUgkEidEblMlkUgkTogUZ4lEInFCpDhLJBKJEyLFWSKRSJwQKc4SiUTihEhxlkgkEidEirNEIpE4IVKcJRKJxAmR4iyRSCROyP8H8GSKdS40Cy8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 400x240 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "sigma = 1 # observation noise\n",
    "num_runs = 10000 # number of experiments\n",
    "\n",
    "K = 100\n",
    "\n",
    "sub = np.random.randint(movies.shape[0], size=K)\n",
    "action_matrix = movies[sub, :]\n",
    "action_matrix = action_matrix[~np.all(action_matrix == 0, axis=1)]\n",
    "K, _ = np.shape(action_matrix)\n",
    "print(f'K = {K}')\n",
    "\n",
    "algs = [\n",
    "  #(\"LinearExploration\", \"pink\", '-',\"LinearExploration\"),\n",
    "  #(\"OD_LinBAI\", \"yellow\", '-',\"OD-LinBAI\"),\n",
    "  (\"BayesGap\", \"green\", '-',\"BayesGap\"),\n",
    "  (\"BAILinTS\", \"cyan\", \"-\", \"BAI-LinTS\"),\n",
    "  (\"BAIUniform\", \"green\", \"-\", \"BAI-Uni\"),\n",
    "  (\"BAIOpt\", \"black\", \"-\", \"BAI-Opt\"),\n",
    "  (\"BAIOptimalDesign\", \"red\", \"-\", \"BAI-Opt-design\"),\n",
    "  (\"GSE\", \"red\", \"-\", \"GSE\"),\n",
    "]\n",
    "\n",
    "exps = [\n",
    "  {\"K\":K}\n",
    "]\n",
    "\n",
    "budgets_ = np.arange(150, 2000, 100)\n",
    "\n",
    "for exp in exps:\n",
    "  \n",
    "  # set parameters of the experiment\n",
    "  for attr, val in exp.items():\n",
    "    globals()[attr] = val\n",
    "  results_ = defaultdict(list)\n",
    "\n",
    "  mu_0 = mu_user \n",
    "  Sigma_0 = np.diag(var_user)\n",
    "  Sigma_0_inv = np.linalg.inv(Sigma_0)\n",
    "\n",
    "  for n in budgets_:\n",
    "      \n",
    "      # Allocation by optimization\n",
    "      w_optim = compute_w_opt(sigma, mu_0, Sigma_0, action_matrix, n, alpha=0.3, num_MC=100) \n",
    "      w_optim /= w_optim.sum()\n",
    "      #print(np.round(w_optim, 1))\n",
    "\n",
    "      # Allocation by optimal design\n",
    "      w_optimal_design = BG_opt(n, K, action_matrix, Sigma_0_inv, sigma).astype(float)\n",
    "      w_optimal_design /= w_optimal_design.sum()\n",
    "\n",
    "      n_ts = K  # warm-up rounds for TS\n",
    "\n",
    "      print('Running experiments with n =', n)\n",
    "      #print('warm up phase = ', n_ts)\n",
    "      print('\\n')\n",
    "            \n",
    "      # bandit environments\n",
    "      envs = []\n",
    "      for run in range(num_runs):\n",
    "        # generate arm means \n",
    "        theta = users[np.random.randint(users.shape[0], size=1), :].reshape(-1)\n",
    "\n",
    "        # initialize bandit environment\n",
    "        env = LinearBanditEnvironment(action_matrix, theta, sigma)\n",
    "\n",
    "        # pass parameters for algorithm initialization (not used in simulation)\n",
    "        env.mu_0 = np.copy(mu_0)\n",
    "        env.Sigma_0 = np.copy(Sigma_0)\n",
    "        env.Sigma_0_inv = np.copy(Sigma_0_inv)\n",
    "        env.n_ts = n_ts\n",
    "        env.w_optimal_design = w_optimal_design\n",
    "        env.w_optim = w_optim\n",
    "        envs.append(env)\n",
    "\n",
    "      # simulation\n",
    "      for alg in algs:\n",
    "        print(alg)\n",
    "        # all runs for a single algorithm\n",
    "        alg_class = globals()[alg[0]]\n",
    "        error_prob, error_indicators = evaluate(alg_class, envs, n)\n",
    "        #evaluate_one(alg_class, envs[0], n)\n",
    "        results_[alg[3]].append(error_indicators)\n",
    "\n",
    "np.save('results/movielens_K={}_d={}.npy'.format(K, d), results_)\n",
    "for alg in algs:\n",
    "    plt.plot(budgets_, np.mean(results_[alg[3]], axis=1), label=alg[3])\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GenHierTS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "662c8e0b62a7efc2d05f2499bcc784ce4e091daa11f92a0001f8c7293a4c0e50"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
